# Promethean Piper & AI pipeline environment template
# Copy this file to `.env` or `.env.local` and fill in any secrets.

# --- Core AI service configuration ---
# Base URL for the Ollama service used by embedding and generation steps.
# Defaults to the local daemon; override with your remote endpoint when needed.
OLLAMA_URL=http://127.0.0.1:11434

# Set to "true" to force-disable Ollama powered features without editing pipeline configs.
OLLAMA_DISABLE=false

# Default reasoning model requested by piper pipelines (symdocs, semverguard, etc.).
DEFAULT_MODEL=qwen3:4b

# Default embedding model used by docops/readmeflow style pipelines.
EMBED_MODEL=nomic-embed-text:latest

# --- SonarQube integration (optional but required for sonar pipeline) ---
# Public SonarCloud host or self-hosted URL.
SONAR_HOST_URL=https://sonarcloud.io
# API token with analysis permissions. Leave blank and export at runtime if you cannot store it here.
SONAR_TOKEN=
# Sonar project key analysed by the pipeline.
SONAR_PROJECT_KEY=promethean

# --- GitHub integration (optional) ---
# Personal access token or GitHub App token for board-review and MCP GitHub tooling.
GITHUB_TOKEN=
