services:
  sonarqube:
    image: sonarqube:25.8.0.112029-community
    container_name: sonarqube
    ports: ["9000:9000"]
    environment:
      - SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true
    volumes:
      - sonarqube_data:/opt/sonarqube/data
      - sonarqube_logs:/opt/sonarqube/logs
      - sonarqube_extensions:/opt/sonarqube/extensions
    restart: always
  chromadb:
    image: chromadb/chroma
    restart: always
    volumes:
      - ./data/chroma:/index_data
    ports:
      - 8000:8000
  ollama:
    image: ollama/ollama:0.11.8
    restart: always
    ports: ["127.0.0.1:11434:11434"]
    gpus: all
    volumes:
      - /usr/share/ollama/.ollama/models:/root/.ollama/models
    environment:
      OLLAMA_HOST: "0.0.0.0:11434"
      OLLAMA_DEBUG: "INFO"
      OLLAMA_LLM_LIBRARY: "cublas"
      CUDA_VISIBLE_DEVICES: "0"
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "all"
    healthcheck:
      test:
        [
          "CMD",
          "bash",
          "-lc",
          "curl -fsS http://127.0.0.1:11434/api/tags >/dev/null && nvidia-smi >/dev/null 2>&1",
        ]
      interval: 10s
      timeout: 5s
      retries: 6
  redis:
    image: redis:6.2-alpine
    container_name: redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --save 60 1 --loglevel warning
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  tei-embeddings:
    profiles: ["ai"]
    image: ghcr.io/huggingface/text-embeddings-inference:1.6
    environment:
      - MODEL_ID=${TEI_MODEL:-nomic-ai/nomic-embed-text-v1.5}
      - NUM_SHARD=1
    ports: ["8081:80"]
    networks: [prom-net]
    volumes:
      - ${HOME}/.cache/huggingface:/root/.cache/huggingface
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -fsS http://127.0.0.1/health >/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6
  mongodb:
    image: mongo:6-jammy
    container_name: mongodb
    restart: always
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password
    volumes:
      - mongo-data:/data/db
  nats:
    profiles: ["messaging"]
    image: nats:2.10
    command: ["-js", "-sd", "/data"]
    volumes:
      - nats_data:/data
    ports: ["4222:4222", "8222:8222"]
    restart: unless-stopped

  haystack:
    profiles: ["ai", "rag"]
    image: deepset/haystack:base
    environment:
      - PIPELINE_YAML=/app/pipelines/default.yaml
    volumes:
      - ./infra/haystack:/app/pipelines
    ports: ["8000:8000"]
    restart: unless-stopped
    depends_on: [opensearch, meilisearch, postgres]

  tei-clip:
    profiles: ["ai", "vision"]
    image: ghcr.io/huggingface/text-embeddings-inference:1.6
    environment:
      - MODEL_ID=${CLIP_MODEL:-openai/clip-vit-large-patch14}
      - TASK=feature-extraction
    ports: ["8082:80"]
    restart: unless-stopped
  qdrant:
    image: qdrant/qdrant:latest
    restart: unless-stopped
    volumes:
      - qdrant-data:/qdrant/storage

  tor:
    image: dperson/torproxy
    restart: unless-stopped

  privoxy:
    image: vimagick/privoxy
    restart: unless-stopped
    environment:
      - FORWARD_SOCKS5=tor:9050
    depends_on: [tor]
  # ---------- Whisper (CUDA) ----------
  whisper-faster-openai:
    image: fedirz/faster-whisper-server:latest-cuda
    environment:
      ASR_ENGINE: whisper
      ASR_MODEL: medium
      ASR_BEAM_SIZE: 5
    volumes:
      - ${HOME}/.cache/huggingface:/root/.cache/huggingface
    gpus: all
    restart: unless-stopped

  # ---------- OVMS (Intel iGPU/NPU) ----------
  ovms-npu:
    image: openvino/model_server:latest
    command: --config_path /config/config.json --rest_port 9000 --port 9000
    volumes:
      - ./infra/ovms/config.json:/config/config.json:ro
      - ./models/ov:/opt/models:ro
    restart: unless-stopped

volumes:
  qdrant-data:
  redis_data:
  sonarqube_data:
  sonarqube_logs:
  sonarqube_extensions:
  mongo-data:

networks:
  prom-net:
    driver: bridge
