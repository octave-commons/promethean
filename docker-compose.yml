services:
  sonarqube:
    image: sonarqube:25.8.0.112029-community
    container_name: sonarqube
    ports: ["9000:9000"]
    environment:
      - SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true
    volumes:
      - sonarqube_data:/opt/sonarqube/data
      - sonarqube_logs:/opt/sonarqube/logs
      - sonarqube_extensions:/opt/sonarqube/extensions
    restart: always
  chromadb:
    image: ${CHROMA_IMAGE:-chromadb/chroma:1.0.21.dev56}
    restart: always
    volumes:
      - ./data/chroma:/index_data
    ports:
      - 127.0.0.1:8000:8000
  ollama:
    image: ollama/ollama:0.11.8
    restart: always
    ports: ["127.0.0.1:11434:11434"]
    gpus: all
    volumes:
      - /usr/share/ollama/.ollama/models:/root/.ollama/models
    environment:
      OLLAMA_HOST: "0.0.0.0:11434"
      OLLAMA_DEBUG: "INFO"
      OLLAMA_LLM_LIBRARY: "cublas"
      CUDA_VISIBLE_DEVICES: "0"
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "all"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:11434/api/tags >/dev/null && nvidia-smi >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 6
  redis:
    image: redis:6.2-alpine
    container_name: redis
    restart: unless-stopped
    ports:
      - "127.0.0.1:6379:6379"
    command: redis-server --save 60 1 --loglevel warning
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  tei-embeddings:
    profiles: ["ai"]
    image: ghcr.io/huggingface/text-embeddings-inference:1.6
    environment:
      - MODEL_ID=${TEI_MODEL:-nomic-ai/nomic-embed-text-v1.5}
      - NUM_SHARD=1
    ports: ["127.0.0.1:8081:80"]
    restart: unless-stopped
  mongodb:
    image: mongo:6-jammy
    container_name: mongodb
    restart: always
    ports:
      - "127.0.0.1:27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password
    volumes:
      - mongo-data:/data/db
  nats:
    profiles: ["messaging"]
    image: nats:2.10
    command: ["-js", "-sd", "/data"]
    volumes:
      - nats_data:/data
    ports: ["4222:4222", "8222:8222"]
    restart: unless-stopped

  haystack:
    profiles: ["ai", "rag"]
    image: ${HAYSTACK_IMAGE:-deepset/haystack:base-v2.17.1}
    environment:
      - PIPELINE_YAML=/app/pipelines/default.yaml
    volumes:
      - ./infra/haystack:/app/pipelines
    ports: ["8000:8000"]
    restart: unless-stopped
    depends_on: [opensearch, meilisearch, postgres]

  tei-clip:
    profiles: ["ai", "vision"]
    image: ghcr.io/huggingface/text-embeddings-inference:1.6
    environment:
      - MODEL_ID=${CLIP_MODEL:-openai/clip-vit-large-patch14}
      - TASK=feature-extraction
    ports: ["127.0.0.1:8082:80"]
    restart: unless-stopped
  qdrant:
    image: ${QDRANT_IMAGE:-qdrant/qdrant:v1.15.4}
    restart: unless-stopped
    volumes:
      - qdrant-data:/qdrant/storage

  tor:
    image: ${TOR_PROXY_IMAGE:-dperson/torproxy@sha256:d161ddddd47b4d2a91b8fe93d61e81b0760c0452ab6983a35ed37452e24004f6}
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "nc -z 127.0.0.1 9050 || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 10

  privoxy:
    image: ${PRIVOXY_IMAGE:-vimagick/privoxy@sha256:10ebc7e0c44f7ad5ef6f92fe929bb48984b0c6fb632439f7255028fc016118b9}
    restart: unless-stopped
    environment:
      - FORWARD_SOCKS5=tor:9050
    depends_on:
      tor:
        condition: service_healthy
  # ---------- Whisper (CUDA) ----------
  whisper-faster-openai:
    image: ${WHISPER_IMAGE:-fedirz/faster-whisper-server:0.6.0-rc.3-cuda}
    environment:
      ASR_ENGINE: whisper
      ASR_MODEL: medium
      ASR_BEAM_SIZE: 5
    volumes:
      - ${HOME}/.cache/huggingface:/root/.cache/huggingface
    gpus: all
    restart: unless-stopped

  # ---------- OVMS (Intel iGPU/NPU) ----------
  ovms-npu:
    image: ${OVMS_IMAGE:-openvino/model_server:2025.2.1}
    command: --config_path /config/config.json --rest_port 9000 --port 9000
    volumes:
      - ./infra/ovms/config.json:/config/config.json:ro
      - ./models/ov:/opt/models:ro
    restart: unless-stopped

volumes:
  nats_data:
  qdrant-data:
  redis_data:
  sonarqube_data:
  sonarqube_logs:
  sonarqube_extensions:
  mongo-data:
