services:
  sonarqube:
    image: sonarqube:25.8.0.112029-community
    container_name: sonarqube
    ports: ["9000:9000"]
    environment:
      - SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true
    volumes:
      - sonarqube_data:/opt/sonarqube/data
      - sonarqube_logs:/opt/sonarqube/logs
      - sonarqube_extensions:/opt/sonarqube/extensions
    restart: always

  chromadb:
    image: ${CHROMA_IMAGE:-chromadb/chroma:1.0.21.dev56}
    restart: always
    volumes:
      - ./data/chroma:/index_data
    ports:
      - 127.0.0.1:8000:8000

  ollama:
    image: ollama/ollama:0.12.3
    restart: always
    ports: ["127.0.0.1:11434:11434"]
    gpus: all
    volumes:
      - /usr/share/ollama/.ollama/models:/root/.ollama/models
    environment:
      OLLAMA_HOST: "0.0.0.0:11434"
      OLLAMA_DEBUG: "INFO"
      OLLAMA_LLM_LIBRARY: "cublas"
      CUDA_VISIBLE_DEVICES: "0"
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "all"
      OLLAMA_CONTEXT_LENGTH: 32000
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -fsS http://127.0.0.1:11434/api/tags >/dev/null && nvidia-smi >/dev/null 2>&1",
        ]
      interval: 10s
      timeout: 5s
      retries: 6

  redis:
    image: redis:6.2-alpine
    container_name: redis
    restart: unless-stopped
    ports:
      - "127.0.0.1:6379:6379"
    command: redis-server --save 60 1 --loglevel warning
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  tei-embeddings:
    profiles: ["ai"]
    image: ghcr.io/huggingface/text-embeddings-inference:1.6
    environment:
      - MODEL_ID=${TEI_MODEL:-nomic-ai/nomic-embed-text-v1.5}
      - NUM_SHARD=1
    ports: ["127.0.0.1:8081:80"]
    networks: [prom-net]
    volumes:
      - ${HOME}/.cache/huggingface:/root/.cache/huggingface
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "bash",
          "-lc",
          "curl -fsS http://127.0.0.1/health >/dev/null || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 6

  mongodb:
    image: mongo:6-jammy
    container_name: mongodb
    restart: always
    ports:
      - "127.0.0.1:27017:27017"
    volumes:
      - mongo-data:/data/db

  nats:
    profiles: ["messaging"]
    image: nats:2.10
    command: ["-js", "-sd", "/data"]
    volumes:
      - nats_data:/data
    ports: ["4222:4222", "8222:8222"]
    restart: unless-stopped

  haystack:
    profiles: ["ai", "rag"]
    image: ${HAYSTACK_IMAGE:-deepset/haystack:base-v2.17.1}
    environment:
      - PIPELINE_YAML=/app/pipelines/default.yaml
    volumes:
      - ./data/haystack:/app/pipelines
    ports: ["8000:8000"]
    restart: unless-stopped
    depends_on: [opensearch, meilisearch, postgres]

  tei-clip:
    profiles: ["ai", "vision"]
    image: ghcr.io/huggingface/text-embeddings-inference:1.6
    environment:
      - MODEL_ID=${CLIP_MODEL:-openai/clip-vit-large-patch14}
      - TASK=feature-extraction
    ports: ["127.0.0.1:8082:80"]
    restart: unless-stopped

  qdrant:
    image: ${QDRANT_IMAGE:-qdrant/qdrant:v1.15.4}
    restart: unless-stopped
    volumes:
      - qdrant-data:/qdrant/storage

  # tor:
  #   image: ${TOR_PROXY_IMAGE:-dperson/torproxy@sha256:d161ddddd47b4d2a91b8fe93d61e81b0760c0452ab6983a35ed37452e24004f6}
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD-SHELL", "nc -z 127.0.0.1 9050 || exit 1"]
  #     interval: 10s
  #     timeout: 3s
  #     retries: 10

  # privoxy:
  #   image: ${PRIVOXY_IMAGE:-vimagick/privoxy@sha256:10ebc7e0c44f7ad5ef6f92fe929bb48984b0c6fb632439f7255028fc016118b9}
  #   restart: unless-stopped
  #   environment:
  #     - FORWARD_SOCKS5=tor:9050
  #   depends_on:
  #     tor:
  #       condition: service_healthy

  # ---------- Whisper (CUDA) ----------
  whisper-faster-openai:
    image: ${WHISPER_IMAGE:-fedirz/faster-whisper-server:0.6.0-rc.3-cuda}
    environment:
      ASR_ENGINE: whisper
      ASR_MODEL: medium
      ASR_BEAM_SIZE: 5
    volumes:
      - ${HOME}/.cache/huggingface:/root/.cache/huggingface
    gpus: all
    restart: unless-stopped
    networks: [prom-net]
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -fsS http://127.0.0.1:8000/health || curl -fsS http://localhost:8000/health",
        ]
      interval: 10s
      timeout: 5s
      retries: 6

  # ---------- Piper TTS (HTTP) ----------
  piper-tts:
    image: ${PIPER_IMAGE:-rhasspy/piper:latest}
    command: >-
      piper --server --host 0.0.0.0 --port 5000 --model /voices/${PIPER_VOICE:-en_US-lessac-medium}.onnx
    ports: ["127.0.0.1:5005:5000"] # optional host exposure for local testing
    volumes:
      - ./data/piper/voices:/voices:ro
    restart: unless-stopped
    networks: [prom-net]
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -fsS http://127.0.0.1:5000/api/tts?text=ping >/dev/null || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 6

  # ---------- ENSO protocol WebSocket server ----------
  enso-server:
    image: node:22-alpine
    working_dir: /app
    command: sh -lc "cd packages/enso-protocol && npm -s --no-fund --no-audit --no-progress --prefix /app run build || true; node /app/packages/enso-protocol/dist/ws-server.js"
    volumes:
      - ./:/app:ro
    environment:
      PORT: 7766
    ports: ["7766:7766"]
    networks: [prom-net]
    restart: unless-stopped
    healthcheck:
      test:
        ["CMD-SHELL", "curl -fsS http://127.0.0.1:7766 >/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6

  # ---------- Browser Gateway (WebRTC <-> ENSO) ----------
  duck-gateway:
    image: node:22-alpine
    working_dir: /app
    command: node packages/enso-browser-gateway/src/server.mjs
    volumes:
      - ./:/app:ro
    environment:
      ENSO_WS_URL: ${ENSO_WS_URL:-ws://host.docker.internal:7766}
      # On Linux hosts you may need to add `--add-host host.docker.internal:host-gateway`
      # when running `docker run` commands to resolve host.docker.internal.
      DUCK_TOKEN: ${DUCK_TOKEN:-}
      ICE_SERVERS: ${ICE_SERVERS:-[]}
    ports: ["8787:8787"]
    networks: [prom-net]
    restart: unless-stopped
    healthcheck:
      test:
        ["CMD-SHELL", "curl -fsS http://127.0.0.1:8787 >/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6

  semgrep:
    image: ${SEMGREP_IMAGE:-semgrep/semgrep:1.92.0}
    working_dir: /src
    volumes:
      - ./:/src:ro # read-only mount is cautious, optional
    entrypoint: []
    command: >
      semgrep scan --config p/default --json
    # Optional environment if you need Semgrep AppSec features
    # environment:
    #   SEMGREP_APP_TOKEN: "${SEMGREP_APP_TOKEN}"

volumes:
  nats_data:
  qdrant-data:
  redis_data:
  sonarqube_data:
  sonarqube_logs:
  sonarqube_extensions:
  mongo-data:

networks:
  prom-net:
    driver: bridge
