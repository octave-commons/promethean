- Cache robots.txt responses per host in the webcrawler service to avoid redundant fetches and respect rate limits.
- Added regression test ensuring the crawler only downloads robots.txt once per host.
