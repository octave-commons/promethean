---
nexus: nexus-ai-chat-importer
plugin_version: "1.2.0"
provider: chatgpt
aliases: "LLM Brain Engagement Study"
conversation_id: 685c4fb9-87c4-8004-bc40-93dff489b089
create_time: 06/25/2025 at 2:36 PM
update_time: 06/25/2025 at 2:37 PM
---

# Title: LLM Brain Engagement Study

Created: 06/25/2025 at 2:36 PM
Last Updated: 06/25/2025 at 2:37 PM
Chat URL: https://chat.openai.com/c/685c4fb9-87c4-8004-bc40-93dff489b089


>[!nexus_user] **User** - 06/25/2025 at 2:36 PM
> I'm interested in your thoughts on this study:
> https://www.brainonllm.com/
<!-- UID: bbb211fc-ad26-49a0-87e4-4b2b86012dbc -->




>[!nexus_agent] **Assistant** - 06/25/2025 at 2:36 PM
> That studyâ€”based at MIT and detailed on brainonllm.comâ€”is a **preprint**, not yet peer-reviewed, so treat its conclusions with serious caution cite.
> 
> ### ðŸ§  Study at a glance
> - **Design**: 54 participants over three essay-writing sessions. Groups: LLM-only (using ChatGPT), web-search, and â€œbrain only.â€ SessionÂ 4 shuffled some participants cite.
> - **Measurements**: EEG scans tracked neural connectivity/cognitive engagement, essay content analyzed via NLP, plus interviews and scoring by humans and an â€œAI judgeâ€ cite.
> - **Findings**:
>  - LLM users showed weaker overall brain connectivity than searchers or unaided writers.
>  - In SessionÂ 4, those transitioning from LLM to brain-only remained underâ€‘engaged; those going from brain to LLM had a boost similar to searchers cite.
>  - LLM group had less essay â€œownership,â€ struggled to recall or quote their own writing cite.
> 
> ### Limitations & caveats
> - **Small, homogenous sample**: Only 54 participants, mostly from nearby academic institutions; just 18 in the key subgroups cite.
> - **Short timeframe**: Conducted over ~4 months without tracking long-term retention or learning cite.
> - **Narrow scope**: Limited to SATâ€‘style essay writing. Does this generalize to other tasks? The authors advise against sweeping conclusions cite.
> - **EEG constraints**: Measures connectivity, not cognitive processing depth. Spatial resolution issues, no fMRI follow-up cite.
> - **Model specificity**: Used ChatGPT (GPTâ€‘4o). Results may differ with different LLMs cite.
> 
> ### Community reaction
> Experts like Tina Austin push back, noting sensationalist headlines like â€œChatGPT kills neuronsâ€ are misleading. The study involved just ~18 people doing a specific taskâ€”steering far from claims of long-term harm cite. On Reddit, the post sparked discussion but little consensus cite.
> 
> ### My take
> The study offers interesting early data suggesting **reduced engagement when offâ€‘loading thinking to an LLM**, but that's **entirely predictable**. The bigger question isn't â€œCan LLMs make us dumber?â€â€”that's clickbaitâ€”but **how** we use them. Passive reliance likely dulls engagement; active, reflective use paired with oversight could still foster deep learning.
> 
> Remember: this is **preliminary**. Itâ€™s a starting point, not a verdict. A broader evidence base is necessary to draw practical conclusions for education or cognitive health.
> 
> ### Practical advice
> - Use LLMs as **thinking partners**, not brain replacements: e.g., brainstorm with AI, then write manually.
> - Structure tasks to **encourage productive struggle**â€”your brain needs friction to build neural connections.
> - If you're seeing dulling effectsâ€”difficulty recalling or explaining your own writingâ€”take a step back from AI and **re-train active engagement**.
> 
> In short: this study raises **flags of concern**, not definitive proof. The real imperative is designing workflows and educational systems that **amplify thinking**, not diminish it.
<!-- UID: 6cd394b8-eb74-4d13-bd37-175e341b0aec -->

---




>[!nexus_user] **User** - 06/25/2025 at 2:37 PM
> Have there been any other studies like this?
<!-- UID: bbb21d01-448e-4173-8c22-20f054fdac20 -->




>[!nexus_agent] **Assistant** - 06/25/2025 at 2:37 PM
> Yes â€” while this MIT â€œYour Brain on ChatGPTâ€ study is one of the first *experimental EEG investigations* into LLM use and writing, it isnâ€™t alone in exploring the intersection of AI use and brain engagement. A growing body of research is emerging, including:
> 
> ---
> 
> ## ðŸ§  Related Studies & Preprints
> 
> ### **NeuroChat: EEGâ€‘guided AI tutoring**
> - A **pilot study** introduced â€œNeuroChat,â€ a prototype system that monitored learnerâ€™s EEG signals in real-time and adjusted AI-generated instruction dynamically. 
> - Compared to a standard LLM chatbot, NeuroChat enhanced **cognitive and subjective engagement**, although it didnâ€™t yet improve immediate learning outcomes citeturn0academia28. 
> - This research leans toward creating *adaptive AI systems* that scaffold rather than replace learner effort.
> 
> ### **EEG + LLM for semantic comprehension**
> - A recent study combined EEG and eye-tracking to analyze real-time brain responses during reading. It then used embeddings from LLMs (like BERT) for semantic decoding, achieving **~60% accuracy** in predicting whether a word is semantically relevant cite. 
> - Though not directly about task engagement, it shows how **neural signals and LLM output interplay**, setting a foundation for future cognitive-AI studies.
> 
> ---
> 
> ## ðŸ“š Broader Context in â€œBrain + Techâ€ Research
> 
> - The emerging field of **neuroergonomics** applies EEG and other brain-imaging tools to study technology's impact on human performance and mental workload cite. 
> - These methods have previously explored brain activity during multitasking, driving, etc., but are now increasingly used to evaluate **LLM usage and AI-assisted cognitive tasks**.
> 
> ---
> 
> ## ðŸ§© Comparison Summary
> 
> | Study / Field | Focus Area | Method | Key Finding |
> |-----------------------------|-----------------------------------------------------|------------------|-------------|
> | *Your Brain on ChatGPT* | Essay writing with/without LLM | EEG, NLP, interview | LLM use â†’ reduced neural connectivity, lower engagement |
> | **NeuroChat** | Adaptive tutoring via EEG feedback | EEG + real-time LLM control | Boosted engagement but no learning gains yet |
> | **EEG + LLM comprehension** | Reading and inferencing tasks with semantic decoding | EEG + eye-tracking + LLM | Feasible to predict word relevance from brain signals |
> | Neuroergonomics | General brain-tech interaction | EEG, fNIRS, etc. | Tech affects cognitive loadâ€”framework for AI studies |
> 
> ---
> 
> ## ðŸ§­ Implications & Whatâ€™s Next
> 
> 1. **Proof of concept**: Beyond essays, EEGâ€‘guided AI tutoring (NeuroChat) shows promise in *adaptive engagement*, though outcomes arenâ€™t straightforward.
> 2. **Nascent stage**: Most studies are small-scale pilot/preprint worksâ€”early stages rather than conclusive evidence.
> 3. **Theoretical expansion**: EEG+LLM for reading comprehension hints at a future where brain-based feedback could dynamically shape AI assistance.
> 4. **Classical grounding**: Neuroergonomics reinforces that understanding cognitive demand remains key to responsibly integrating AI tools.
> 
> ---
> 
> ### ðŸ—£ï¸ My Take
> 
> - Researchers are already *experimentalizing what â€˜thinking with AIâ€™ looks like* using neural dataâ€”not just behavior or test scores.
> - The trend is towards systems that *sense under-engagement and adjust*, rather than merely providing predictive output.
> - But: **sample sizes are small**, contexts narrow, and adaptive systems like NeuroChat havenâ€™t yet backed improvements in learning outcomes.
> - These early signals are promising, yet weâ€™re far from generalizing about â€œLLMs rewiring brainsâ€ in daily life.
> 
> ---
> 
> ### âœ… Bottom Line
> 
> Yes â€” this MIT study is part of a budding scientific conversation exploring how AI affects real-time brain engagement. Follow-up work is venturing into **adaptive, EEG-responsive AI**, and **neural-semantic studies**. But all are early-stage and limited in scale. The core challenge remains: translating neural insights into **practical, scalable AI workflows that enhance learning** instead of dulling it.
<!-- UID: d9f37d9c-0262-4478-abc9-a5fc8e4f0d0f -->

---


