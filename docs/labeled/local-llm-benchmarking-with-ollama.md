---
uuid: a5baf674-4b06-4af2-886e-9228909d814a
created_at: '2025-10-07T21:55:08Z'
title: 2025.10.07.21.55.08
filename: Local LLM Benchmarking with Ollama
description: >-
  This guide explores running and benchmarking local LLMs using Ollama, focusing
  on models like Qwen3, DeepSeek, and Gemma. It covers practical steps for
  evaluation and benchmarking on limited hardware, emphasizing models that fit
  within GPU memory constraints.
tags:
  - ollama
  - local-llm
  - benchmarking
  - qwen3
  - deepseek
  - gemma
  - gpu-constrained
---
https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker
https://cline.bot/blog/local-models-amd
https://www.reddit.com/r/LocalLLaMA/comments/1o0ifyr/glm_46_air_is_coming/
https://docs.unsloth.ai/new/gpt-oss-how-to-run-and-fine-tune
https://docs.unsloth.ai/models/deepseek-v3.1-how-to-run-locally
https://github.com/matt-c1/llama-3-quant-comparison?tab=readme-ov-file
https://ollama.com/library/smollm2
https://github.com/hendrycks/test
https://github.com/unslothai/unsloth
https://docs.unsloth.ai/models/gemma-3-how-to-run-and-fine-tune/gemma-3n-how-to-run-and-fine-tune
https://ollama.com/library/gemma3n
https://huggingface.co/BasedBase/Qwen3-Coder-30B-A3B-Instruct-480B-Distill-V2/discussions/1
https://ollama.com/search?q=gemma3-tools
https://huggingface.co/openbmb/MiniCPM-V-4_5-gguf
https://ollama.com/openbmb/minicpm-v4.5
https://github.com/OpenSQZ/MiniCPM-V-CookBook
https://minicpm-o.readthedocs.io/en/latest/index.html
https://media.discordapp.net/attachments/1128867684130508875/1425319710039212093/radar_minicpm_v45.png?ex=68e727ec&is=68e5d66c&hm=15f8e41dd88927df445b43867d28bb551d098b97275b160543a40f5def251a7c&=&format=webp&quality=lossless&width=1148&height=1081
https://cdn.discordapp.com/attachments/1128867684130508875/1425319191015198720/image.png?ex=68e72770&is=68e5d5f0&hm=7e738df53d0345390045d965a649719229345f4f5e2fdea4af8a06fe0d91ee50&
https://github.com/ollama/ollama/pull/12526
https://www.ollama.com/library/qwen2.5vl
https://www.ollama.com/library/granite3.2-vision
https://www.ollama.com/library/granite3.3
https://www.ollama.com/library/granite3.1-moe
https://www.ollama.com/library/granite-code
https://www.ollama.com/library/granite3.2
https://www.ollama.com/library/granite3.1-dense
https://www.ollama.com/library/granite-embedding
https://www.ollama.com/library/granite4
## Might barely fit in my gpu and run at an *okay spee*
Probably only going to be useful for evaluation and  benchmarking
https://www.ollama.com/library/qwen3-coder

https://www.ollama.com/library/deepseek-r1
https://www.ollama.com/goekdenizguelmez/JOSIEFIED-Qwen3
https://www.ollama.com/huihui_ai/qwen3-abliterated
https://github.com/Sumandora/remove-refusals-with-transformers
https://github.com/TransformerLensOrg/TransformerLens
https://distill.pub/2020/circuits/zoom-in/
https://docs.openwebui.com/
https://docs.openwebui.com/tutorials/web-search/searxng#docker-compose-setup
