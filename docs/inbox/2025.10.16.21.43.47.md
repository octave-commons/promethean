I. Summary
A. Reviewed `.opencode/plugin` code: three DualStore-backed plugins (event capture, async sub-agents, indexer client) are solid but have type/timestamp inconsistencies and a few resilience gaps.
B. Proposed two new packages: `@promethean/dualstore-http` (REST + SSE façade) and `@promethean/dualstore-sse-client` (tiny web client). Both wrap the same DualStore collections: `session_messages`, `agent_tasks`, `opencode_events`.
C. Chosen stack: TypeScript + Fastify (server), native `EventSource` (client). Auth via optional bearer, CORS allow-list, heartbeats + reconnection.
D. Produced an API spec (endpoints, payloads, SSE events) and implementation skeletons (server + client) that fit our GPL-3.0 licensing and Kanban DoD.
E. Write access is currently blocked in this workspace, so I didn’t commit scaffolds; actions below include a task to grant repo write perms and a readiness checklist.

II. Analysis
A. Timestamp mismatch risk: code stores `timestamp` as both ISO strings and numbers; can break ordering in persistence/SSE.
B. SSE source-of-truth: DualStore lacks push streams; initial version must poll; risk of lag/duplication without idempotency keys.
C. Backpressure/rate limits: public REST+SSE could be DoS vectors; need simple quotas and request caps.
D. Auth model: bearer-only is minimal; may need rotating keys or mTLS later.
E. Collection schema variability: metadata shape differs per producer; API must not overfit.
F. Search filters: current plugins assume `getMostRelevant` and `getMostRecent` accept filters; verify across stores.
G. Agent task existence check is O(n) on “most recent 100”; server should offer fast by-id read.
H. WIP cap: two new packages + hardening; keep ≤3 concurrent items.
I. Write permission blocker: cannot land files; propose process task for access.
J. Versioning: pin to `@promethean/persistence` public surface (no `dist` internals).

III. Decisions
A. Packages to create:
• `@promethean/dualstore-http` — REST & SSE façade for `session_messages`, `agent_tasks`, `opencode_events` (configurable).
• `@promethean/dualstore-sse-client` — tiny TS browser client + Node polyfill recipe.
B. Server framework: Fastify + `@fastify/cors`; JSON only; OpenAPI stub included.
C. SSE delivery: polling DualStore per collection with last-seen watermark; heartbeats every 15s; reconnection via `Last-Event-ID`.
D. Auth & CORS: optional bearer (`Authorization: Bearer <token>`), allow-list via env.
E. Timestamps standardized to ISO 8601 strings for all new writes/reads.
F. License: GPL-3.0-or-later, headers in all files.
G. Minimal rate limiting (IP + token buckets) before public exposure.

IV. Artifacts
A. Code review notes (targeted)

1. `.opencode/plugin/async-sub-agents-final.ts`
   • Inconsistent timestamps: `agentTaskStore.insert` uses both ISO strings and numbers. Standardize to ISO string (Decision E).
   • `verifyAgentExists` scans recent tasks; prefer a `getById` (HTTP façade will provide).
   • `monitorTasks` interval cleared on SIGINT—good—but consider plugin shutdown hooks beyond SIGINT.
   • Completion detection is regex-based on last text part; OK but brittle—consider explicit tool signals later.

2. `.opencode/plugin/event-capture-simplified.ts`
   • Good extraction + truncation; keeps events searchable.
   • Assumes `getMostRecent(limit, filter)` supports nested `metadata.*` filters—verify in persistence.
   • Metadata size may balloon; ensure `rawEvent` truncation bound stays conservative (currently 10k chars).

3. `.opencode/plugin/indexer-service.ts`
   • Clean HTTP client wrapper for indexer; pattern is a good template for our `dualstore-http` client mode.
   • Surfaces detailed admin tools; we’ll mirror health/status endpoints in our server.

B. API Spec (v1) — `@promethean/dualstore-http`
Base: `/:version` (default `/v1`)
Collections (default): `session_messages`, `agent_tasks`, `opencode_events` (override via env).

REST

* `GET /v1/health` → `{ ok: true, collections: string[] }`
* `GET /v1/collections` → `string[]`
* `GET /v1/:collection/recent?limit=50&filter=<base64json>` → `{ items: Doc[], next?: Cursor }`
* `GET /v1/:collection/search?q=<string>&k=8&filter=<base64json>` → `{ items: Doc[] }`
* `GET /v1/:collection/:id` → `Doc | 404` *(best-effort; server may require index if DualStore doesn’t support by-id)*
* `POST /v1/:collection` body `{ text: string, timestamp?: string, metadata?: object }` → `{ id: string }`

SSE

* `GET /v1/:collection/stream?since=<iso|eventId>`
  • Events:

  * `event: insert` `data: Doc`
  * `event: heartbeat` `data: {"t":"<iso>"}`
    • Headers: `Last-Event-ID` supported for resume.

Types

```
type Doc = {
  id: string
  text: string
  timestamp: string   // ISO 8601
  metadata?: Record<string, any>
};
```

Security & Limits

* Auth: optional bearer; if set, all endpoints require it.
* CORS: allow-list via `CORS_ORIGIN` (CSV).
* Limits: `limit <= 200`, payload ≤ 64KB, SSE clients per IP ≤ 10 (config).

Env

```
PORT=4261
AUTH_TOKEN=optional
CORS_ORIGIN=https://app.example.com,https://localhost:5173
COLLECTIONS=session_messages,agent_tasks,opencode_events
```

C. Implementation skeletons (pseudo-code)

Server (Fastify)

```ts
// server.ts (sketch)
import Fastify from 'fastify';
import cors from '@fastify/cors';
import { DualStoreManager } from '@promethean/persistence';

const app = Fastify({ logger: true });
await app.register(cors, { origin: allowedOrigins });

const registry = await bootstrapCollections(env.COLLECTIONS);
// registry: Map<string, DualStoreManager<'text','timestamp'>>

app.get('/v1/health', () => ({ ok: true, collections: [...registry.keys()] }));
app.get('/v1/collections', () => [...registry.keys()]);

app.get('/v1/:c/recent', async (req, rep) => {
  const store = mustGetStore(registry, req.params.c);
  const filter = parseFilter(req.query.filter);
  const k = clamp(toInt(req.query.limit ?? 50), 1, 200);
  const items = await store.getMostRecent(k, filter);
  return { items: normalizeISO(items) };
});

app.get('/v1/:c/search', async (req) => {
  const store = mustGetStore(registry, req.params.c);
  const k = clamp(toInt(req.query.k ?? 8), 1, 50);
  const q = String(req.query.q ?? '');
  const filter = parseFilter(req.query.filter);
  const items = await store.getMostRelevant([q], k, filter);
  return { items: normalizeISO(items) };
});

app.post('/v1/:c', async (req) => {
  const store = mustGetStore(registry, req.params.c);
  const doc = normalizeIncoming(req.body); // ensure ISO timestamp
  const id  = await store.insert(doc);
  return { id };
});

// SSE: naive polling loop per connection with watermark
app.get('/v1/:c/stream', async (req, rep) => {
  sseHeaders(rep);
  const store = mustGetStore(registry, req.params.c);
  const since = parseSince(req.query.since, req.headers['last-event-id']);
  const loop = new PollLoop(store, since, rep.raw);
  loop.start();  // emits `insert` + `heartbeat`
  rep.raw.on('close', () => loop.stop());
});

app.listen({ port: env.PORT });
```

Client (browser)

```ts
// client.ts (sketch)
export function createDualStoreStream({ baseUrl, collection, token, lastEventId, onInsert, onHeartbeat }) {
  const url = new URL(`${baseUrl}/v1/${collection}/stream`);
  const es = new EventSource(url.toString(), { withCredentials: false });
  if (lastEventId) (es as any).lastEventId = lastEventId;

  es.addEventListener('insert', (e) => onInsert?.(JSON.parse((e as MessageEvent).data)));
  es.addEventListener('heartbeat', (e) => onHeartbeat?.(JSON.parse((e as MessageEvent).data)));

  es.onerror = () => { /* optional backoff & reconnect wrapper if EventSource polyfill used */ };
  return { close: () => es.close() };
}

export class DualStoreHttp {
  constructor(private baseUrl: string, private token?: string) {}
  private headers() { return this.token ? { Authorization: `Bearer ${this.token}` } : {}; }

  listCollections() { return fetchJSON(`${this.baseUrl}/v1/collections`, this.headers()); }
  recent(c: string, limit=50, filter?: object) { /* GET recent with base64 filter */ }
  search(c: string, q: string, k=8, filter?: object) { /* GET search */ }
  insert(c: string, doc: { text: string; timestamp?: string; metadata?: any }) { /* POST */ }
}
```

D. OpenAPI stub (excerpt)

```yaml
openapi: 3.0.3
info:
  title: DualStore HTTP
  version: 0.1.0
paths:
  /v1/{collection}/recent:
    get:
      parameters:
        - in: path; name: collection; required: true; schema: { type: string }
        - in: query; name: limit; schema: { type: integer, maximum: 200, default: 50 }
        - in: query; name: filter; schema: { type: string, description: base64-encoded JSON }
      responses:
        '200': { description: OK }
  /v1/{collection}/stream:
    get:
      responses:
        '200': { description: text/event-stream }
```

E. Package scaffolds (outline)

1. `@promethean/dualstore-http`

   * `src/server.ts`, `src/sse.ts`, `src/env.ts`, `openapi.yaml`
   * `package.json` deps: `fastify`, `@fastify/cors`, `zod`, `@types/node`, `tsx`
   * scripts: `dev`, `build`, `start`
2. `@promethean/dualstore-sse-client`

   * `src/index.ts` (EventSource wrapper + thin REST client)
   * `package.json` deps: `zod` (optional), peer: none
   * `README.md` quick start & examples

F. Acceptance criteria (for each package)

* Unit tests for: search/recent/insert; SSE emits ordered inserts; heartbeats sent; reconnection resumes from `Last-Event-ID`.
* DoD: OpenAPI published; license headers; lint/typecheck/test passing; minimal load test (100 SSE clients) with no memory growth in 5 min.

V. Actions

1. Create Task

* `title:` Scaffold dualstore HTTP façade and SSE endpoints
* `tags:` [infra, api, persistence, sse]
* `priority:` P0
* `complexity:` M
* `urgency:` Now

2. Review Task Transition

* `title:` Scaffold dualstore HTTP façade and SSE endpoints
* `current_status:` Backlog
* `valid_transitions:` [Backlog → Ready, Backlog → Blocked]
* `desired_transition:` Backlog → Ready
* `rationale:` Requirements & acceptance criteria are defined; env/config documented; WIP under cap (≤3). Write access remains a separate blocker task.

3. Produce Documentation Artifact

* `type:` RFC
* `title:` RFC: DualStore-over-HTTP & SSE
* `rationale:` Align server/client shape, auth, timestamps, and SSE mechanics across teams.
* `abstract:` Define a minimal, composable façade exposing DualStore collections over REST and SSE, with standardized ISO timestamps, bearer auth, and CORS. Includes OpenAPI surface, SSE contract, backpressure and rate-limit notes, and migration plan once push-based change streams are available.

4. Create Task — Grant repo write permissions for package scaffolds

* Scope: unblock code landings; current error: “Authorization denied: Role 'guest' lacks required permission level: write”.
* Tags: [ops, access] • Priority: P0 • Complexity: S • Urgency: Now

5. Start Task — Timestamp normalization in producers

* Update plugins to store ISO string timestamps (no numbers).
* Tags: [persistence, consistency] • Priority: P1 • Complexity: S • Urgency: Soon

6. Evaluate — DualStore filter semantics

* Verify `getMostRecent(limit, filter)` and `getMostRelevant(queries, k, filter)` accept nested `metadata.*`. If not, propose adapter.
* Tags: [persistence, api] • Priority: P1 • Complexity: S • Urgency: Soon

7. Run checks — Lint/typecheck on `.opencode/plugin`

* Command plan: `pnpm -w lint`, `pnpm -w tsc --noEmit`. Capture any type/time warnings tied to timestamp usage.
* Tags: [quality] • Priority: P2 • Complexity: XS • Urgency: Later

8. Board triage — Add `@promethean/dualstore-sse-client` package skeleton task

* Tags: [frontend, sdk] • Priority: P1 • Complexity: S • Urgency: Soon

If you want, I can convert the RFC + OpenAPI stub into repo-ready files and a PR description once write access is granted, and I’ll keep the WIP at or under the cap.
