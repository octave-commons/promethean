---
uuid: d527c05d-22e8-4493-8f29-ae3cb67f035b
created_at: 2025.08.31.11.21.12.md
filename: Pure-Node Crawl Stack with Playwright and Crawlee
description: >-
  A local, self-hosted JavaScript crawling solution using Playwright and Crawlee
  for data extraction. Supports optional local proxy for traffic control and
  integrates with Meilisearch/OpenSearch for indexing via HTTP.
tags:
  - JavaScript
  - Playwright
  - Crawlee
  - Meilisearch
  - OpenSearch
  - Local Proxy
  - Data Extraction
  - Self-Hosted
related_to_title:
  - Per-Domain Policy System for JS Crawler
  - Vectorial Exception Descent
  - WebSocket Gateway Implementation
  - i3-config-validation-methods
  - Model Selection for Lightweight Conversational Tasks
  - sibilant-metacompiler-overview
  - State Snapshots API and Transactional Projector
  - Pipeline Enhancements
  - Interop and Source Maps
  - Post-Linguistic Transhuman Design Frameworks
  - promethean-system-diagrams
  - Universal Lisp Interface
  - Matplotlib Animation with Async Execution
  - RAG UI Panel with Qdrant and PostgREST
  - mystery-lisp-search-session
  - komorebi-group-window-hack
  - Promethean-native config design
  - universal-intention-code-fabric
  - compiler-kit-foundations
  - Exception Layer Analysis
  - SentenceProcessing
  - Language-Agnostic Mirror System
  - Sibilant Meta-Prompt DSL
  - Event Bus MVP
  - Cross-Language Runtime Polymorphism
  - js-to-lisp-reverse-compiler
  - ecs-scheduler-and-prefabs
  - Chroma Toolkit Consolidation Plan
  - 'Polyglot S-expr Bridge: Python-JS-Lisp Interop'
  - Lisp-Compiler-Integration
  - shared-package-layout-clarification
  - Promethean Web UI Setup
  - Promethean Full-Stack Docker Setup
  - 'Promethean Pipelines: Local TypeScript-First Workflow'
  - Migrate to Provider-Tenant Architecture
  - refactor-relations
  - Refactor 05-footers.ts
  - ecs-offload-workers
  - Local-Offline-Model-Deployment-Strategy
  - set-assignment-in-lisp-ast
  - Pure TypeScript Search Microservice
  - Promethean Event Bus MVP v0.1
  - Recursive Prompt Construction Engine
  - Chroma-Embedding-Refactor
  - Promethean Agent Config DSL
  - Shared Package Structure
  - observability-infrastructure-setup
  - prom-lib-rate-limiters-and-replay-api
  - Mongo Outbox Implementation
  - markdown-to-org-transpiler
  - polyglot-repl-interface-layer
  - Promethean Agent DSL TS Scaffold
  - Local-First Intention→Code Loop with Free Models
  - Event Bus Projections Architecture
  - heartbeat-fragment-demo
  - Local-Only-LLM-Workflow
  - balanced-bst
  - Promethean Notes
  - i3-bluetooth-setup
  - field-dynamics-math-blocks
  - eidolon-field-math-foundations
  - field-node-diagram-set
  - homeostasis-decay-formulas
  - Ice Box Reorganization
  - file-watcher-auth-fix
  - Promethean Infrastructure Setup
  - Prometheus Observability Stack
  - Dynamic Context Model for Web Components
  - Promethean_Eidolon_Synchronicity_Model
  - sibilant-macro-targets
  - Ghostly Smoke Interference
  - ripple-propagation-demo
  - System Scheduler with Resource-Aware DAG
  - Ollama-LLM-Provider-for-Pseudo-Code-Transpiler
related_to_uuid:
  - c03020e1-e3e7-48bf-aa7e-aa740c601b63
  - d771154e-a7ef-44ca-b69c-a1626cf94fbf
  - e811123d-5841-4e52-bf8c-978f26db4230
  - d28090ac-f746-4958-aab5-ed1315382c04
  - d144aa62-348c-4e5d-ae8f-38084c67ceca
  - 61d4086b-4adf-4e94-95e4-95a249cd1b53
  - 509e1cd5-367c-4a9d-a61b-cef2e85d42ce
  - e2135d9f-c69d-47ee-9b17-0b05e98dc748
  - cdfac40c-00e4-458f-96a7-4c37d0278731
  - 6bcff92c-4224-453d-9993-1be8d37d47c3
  - b51e19b4-1326-4311-9798-33e972bf626c
  - b01856b4-999f-418d-8009-ade49b00eb0f
  - 687439f9-ad1e-40a4-8a32-3a1b4ac7c017
  - e1056831-ae0c-460b-95fa-4cf09b3398c6
  - 513dc4c7-e045-4123-ba2e-cf5ef0b7b4a3
  - dd89372d-10de-42a9-8c96-6bc13ea36d02
  - ab748541-020e-4a7e-b07d-28173bd5bea2
  - c14edce7-0656-45b2-aaf3-51f042451b7d
  - 01b21543-7e03-4129-8fe4-b6306be69dee
  - 21d5cc09-b005-4ede-8f69-00b4b0794540
  - 681a4ab2-8fef-4833-a09d-bceb62d114da
  - d2b3628c-6cad-4664-8551-94ef8280851d
  - af5d2824-faad-476c-a389-e912d9bc672c
  - 534fe91d-e87d-4cc7-b0e7-8b6833353d9b
  - c34c36a6-80c9-4b44-a200-6448543b1b33
  - 58191024-d04a-4520-8aae-a18be7b94263
  - c62a1815-c43b-4a3b-88e6-d7fa008a155e
  - 5020e892-8f18-443a-b707-6d0f3efcfe22
  - 63a1cc28-b85c-4ce2-b754-01c2bc0c0bc3
  - cfee6d36-b9f5-4587-885a-cdfddb4f054e
  - 36c8882a-badc-4e18-838d-2c54d7038141
  - bc5172ca-7a09-42ad-b418-8e42bb14d089
  - 2c2b48ca-1476-47fb-8ad4-69d2588a6c84
  - 6b63edca-7637-4fb0-bc85-d498c31cc46e
  - 54382370-1931-4a19-a634-46735708a9ea
  - 41ce0216-f8cc-4eed-8d9a-fcc25be21425
  - 80d4d883-59f9-401b-8699-7a2723148b1e
  - 6498b9d7-bd35-4bd3-89fb-af1c415c3cd1
  - ad7f1ed3-c9bf-4e85-9eeb-6cc4b53155f3
  - c5fba0a0-9196-468d-a0f3-51c99e987263
  - d17d3a96-c84d-4738-a403-6c733b874da2
  - fe7193a2-a5f7-4b3c-bea0-bd028815fc2c
  - babdb9eb-3b15-48a7-8a22-ecc53af7d397
  - 8b256935-02f6-4da2-a406-bf6b8415276f
  - 2c00ce45-08cf-4b81-9883-6157f30b7fae
  - 66a72fc3-4153-41fc-84bd-d6164967a6ff
  - b4e64f8c-4dc9-4941-a877-646c5ada068e
  - aee4718b-9f8b-4635-a0c1-ef61c9bea8f1
  - 9c1acd1e-c6a4-4a49-a66f-6da8b1bc9333
  - ab54cdd8-13ce-4dcb-a9cd-da2d86e0305f
  - 9c79206d-4cb9-4f00-87e0-782dcea37bc7
  - 5158f742-4a3b-466e-bfc3-d83517b64200
  - 871490c7-a050-429b-88b2-55dfeaa1f8d5
  - cf6b9b17-bb91-4219-aa5c-172cba02b2da
  - dd00677a-2280-45a7-91af-0728b21af3ad
  - 9a8ab57e-507c-4c6b-aab4-01cea1bc0501
  - d3e7db72-2e07-4dae-8920-0e07c499a1e5
  - 1c4046b5-742d-4004-aec6-b47251fef5d6
  - 5e408692-0e74-400e-a617-84247c7353ad
  - 7cfc230d-8ec2-4cdb-b931-8aec26de2a00
  - 008f2ac0-bfaa-4d52-9826-2d5e86c0059f
  - 22b989d5-f4aa-4880-8632-709c21830f83
  - 37b5d236-2b3e-4a95-a4e8-31655c3023ef
  - 291c7d91-da8c-486c-9bc0-bd2254536e2d
  - 9044701b-03c9-4a30-92c4-46b1bd66c11e
  - 6deed6ac-2473-40e0-bee0-ac9ae4c7bff2
  - e90b5a16-d58f-424d-bd36-70e9bd2861ad
  - f7702bf8-f7db-473c-9a5b-8dbf66ad3b9e
  - 2d6e5553-8dc4-497f-bf45-96f8ca00a6f6
  - c5c9a5c6-427d-4864-8084-c083cd55faa0
  - b6ae7dfa-0c53-4eb9-aea8-65072b825bee
  - 8430617b-80a2-4cc9-8288-9a74cb57990b
  - ba244286-4e84-425b-8bf6-b80c4eb783fc
  - b362e12e-2802-4e41-9a21-6e0c7ad419a2
references:
  - uuid: d144aa62-348c-4e5d-ae8f-38084c67ceca
    line: 103
    col: 0
    score: 0.87
  - uuid: b01856b4-999f-418d-8009-ade49b00eb0f
    line: 137
    col: 0
    score: 0.86
  - uuid: dd89372d-10de-42a9-8c96-6bc13ea36d02
    line: 132
    col: 0
    score: 0.85
  - uuid: c03020e1-e3e7-48bf-aa7e-aa740c601b63
    line: 188
    col: 0
    score: 0.88
  - uuid: 01b21543-7e03-4129-8fe4-b6306be69dee
    line: 590
    col: 0
    score: 0.85
  - uuid: d771154e-a7ef-44ca-b69c-a1626cf94fbf
    line: 95
    col: 0
    score: 0.89
  - uuid: e811123d-5841-4e52-bf8c-978f26db4230
    line: 631
    col: 0
    score: 0.88
  - uuid: 61d4086b-4adf-4e94-95e4-95a249cd1b53
    line: 52
    col: 0
    score: 0.87
  - uuid: 509e1cd5-367c-4a9d-a61b-cef2e85d42ce
    line: 303
    col: 0
    score: 0.87
  - uuid: b51e19b4-1326-4311-9798-33e972bf626c
    line: 169
    col: 0
    score: 0.85
  - uuid: 687439f9-ad1e-40a4-8a32-3a1b4ac7c017
    line: 16
    col: 0
    score: 0.86
  - uuid: 513dc4c7-e045-4123-ba2e-cf5ef0b7b4a3
    line: 106
    col: 0
    score: 0.85
  - uuid: c14edce7-0656-45b2-aaf3-51f042451b7d
    line: 388
    col: 0
    score: 0.85
  - uuid: e2135d9f-c69d-47ee-9b17-0b05e98dc748
    line: 169
    col: 0
    score: 0.87
  - uuid: 6bcff92c-4224-453d-9993-1be8d37d47c3
    line: 269
    col: 0
    score: 0.86
  - uuid: e1056831-ae0c-460b-95fa-4cf09b3398c6
    line: 349
    col: 0
    score: 0.85
  - uuid: ab748541-020e-4a7e-b07d-28173bd5bea2
    line: 305
    col: 0
    score: 0.85
  - uuid: d28090ac-f746-4958-aab5-ed1315382c04
    line: 28
    col: 0
    score: 0.87
  - uuid: cdfac40c-00e4-458f-96a7-4c37d0278731
    line: 498
    col: 0
    score: 0.87
---
Heard. JS or bust. Here’s a **pure-Node** crawling stack: Playwright + Crawlee, no Python anywhere, no SaaS, no tokens. Local proxy optional. Data lands as JSONL and (optionally) streams into Meilisearch/OpenSearch—both via HTTP from Node. ^ref-d527c05d-1-0

---

# `docker-compose.yml` (crawl-only, JS)

Drop this into your compose (or a standalone file) and run with the `crawl-js` profile. ^ref-d527c05d-7-0

```yaml
version: "3.9"

networks:
  prom-net:
    driver: bridge

volumes:
  crawl_data:
  crawl_storage:     # crawlee request queue + dataset persistence
  crawl_workspace:

services:
  # Optional local proxy (good for central throttle/egress control)
  squid:
    profiles: ["crawl-js","proxy"]
    image: squidfunk/squid:latest
    ports: ["3128:3128"]
    volumes:
      - ./infra/squid/squid.conf:/etc/squid/squid.conf:ro
    networks: [prom-net]
    restart: unless-stopped

  # JS crawler (Playwright chromium baked in)
  crawler-js:
    profiles: ["crawl-js"]
    image: mcr.microsoft.com/playwright:v1.47.2-jammy
    working_dir: /workspace
    environment:
      # --- core crawl knobs (override via env or .env) ---
      - CRAWL_SEED=https://example.org
      - CRAWL_MAX_PAGES=200
      - CRAWL_CONCURRENCY=6
      - CRAWL_REQS_PER_MIN=120
      - RESPECT_ROBOTS=true
      - SAME_DOMAIN_ONLY=true
      - ALLOW_LIST= # comma-separated regex; empty = allow all
      - DENY_LIST=  # comma-separated regex; empty = deny none
      - PROXY_URL=http://squid:3128
      - OUTPUT_DIR=/data
      - SITEMAP_DISCOVER=true
      - RSS_DISCOVER=true
      - DEDUP_NORMALIZE=true
      # --- sinks (all local, optional) ---
      - SINK_OPENSEARCH_URL=        # e.g. http://opensearch:9200
      - SINK_OPENSEARCH_INDEX=documents
      - SINK_MEILI_URL=             # e.g. http://meilisearch:7700
      - SINK_MEILI_KEY=             # optional local master key
      - SINK_MEILI_INDEX=documents
    command: bash -lc "npm ci && node src/crawl.js"
    volumes:
      - ./infra/crawler-js:/workspace:rw        # your code
      - crawl_data:/data                        # JSONL output
      - crawl_storage:/workspace/storage        # Crawlee persistence
    depends_on:
      - squid
    networks: [prom-net]
    restart: "no"
```
^ref-d527c05d-9-0

---

# File tree
 ^ref-d527c05d-73-0
```
infra/
├─ squid/
│  └─ squid.conf
└─ crawler-js/
   ├─ package.json
   ├─ package-lock.json      # optional
   └─ src/
      ├─ crawl.js
      ├─ sinks.js
      ├─ utils.js
      └─ ua.json            # small rotating UA set
^ref-d527c05d-73-0
```

---

# `infra/squid/squid.conf` (LAN-only, no caching) ^ref-d527c05d-91-0

```conf
http_port 3128
acl localnet src 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16
http_access allow localnet
http_access deny all
dns_v4_first on
pipeline_prefetch off
request_header_access Authorization deny all
reply_header_access Server deny all
^ref-d527c05d-91-0
cache deny all
```

---
 ^ref-d527c05d-107-0
# `infra/crawler-js/package.json`

```json
{
  "name": "crawler-js",
  "private": true,
  "type": "module",
  "scripts": {
    "start": "node src/crawl.js"
  },
  "dependencies": {
    "crawlee": "^3.9.2",
    "playwright": "^1.47.2",
    "robots-parser": "^3.0.1",
    "node-fetch": "^3.3.2",
    "fast-xml-parser": "^4.5.0",
    "p-limit": "^6.2.0"
^ref-d527c05d-107-0
  }
}
```

--- ^ref-d527c05d-130-0

# `infra/crawler-js/src/utils.js`

```js
import robotsParser from 'robots-parser';
import fetch from 'node-fetch';

export const sleep = (ms) => new Promise(r => setTimeout(r, ms));

export function compileRegexList(csv) {
  if (!csv) return [];
  return csv.split(',').map(s => s.trim()).filter(Boolean).map(s => new RegExp(s, 'i'));
}

export function normalizeUrlForDedup(url) {
  try {
    const u = new URL(url);
    u.hash = '';
    u.searchParams.sort();
    // Strip common tracking params
    ['utm_source','utm_medium','utm_campaign','utm_term','utm_content','gclid','igshid','fbclid'].forEach(p => u.searchParams.delete(p));
    return u.toString();
  } catch { return url; }
}

export async function buildRobotsForOrigin(origin, proxyAgent) {
  const robotsUrl = `${origin}/robots.txt`;
  try {
    const res = await fetch(robotsUrl, { agent: proxyAgent, timeout: 10000 });
    const txt = res.ok ? await res.text() : '';
    return robotsParser(robotsUrl, txt);
  } catch {
    return robotsParser(robotsUrl, '');
  }
}

export function decideUrl(url, { sameDomainOnly, seedOrigin, allow, deny }) {
  try {
    const u = new URL(url);
    if (sameDomainOnly && u.origin !== seedOrigin) return false;
    if (deny.some(rx => rx.test(url))) return false;
    if (allow.length && !allow.some(rx => rx.test(url))) return false;
^ref-d527c05d-130-0
    return true;
  } catch { return false; }
}
```
 ^ref-d527c05d-178-0
---

# `infra/crawler-js/src/sinks.js`

```js
import fetch from 'node-fetch';

export async function sinkToOpenSearch(docs, { url, index }) {
  if (!url || !index || docs.length === 0) return;
  const nd = docs.flatMap(d => [{ index: { _index: index } }, d]).map(x => JSON.stringify(x)).join('\n') + '\n';
  const res = await fetch(`${url}/_bulk`, { method: 'POST', headers: { 'Content-Type': 'application/x-ndjson' }, body: nd });
  if (!res.ok) {
    const t = await res.text().catch(()=>'');
    console.error('OpenSearch bulk failed', res.status, t.slice(0, 400));
  }
}

export async function sinkToMeili(docs, { url, index, apiKey }) {
  if (!url || !index || docs.length === 0) return;
  const res = await fetch(`${url}/indexes/${index}/documents`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json', ...(apiKey ? { 'Authorization': `Bearer ${apiKey}` } : {}) },
    body: JSON.stringify(docs)
  });
  if (!res.ok) {
^ref-d527c05d-178-0
    const t = await res.text().catch(()=>'');
    console.error('Meili push failed', res.status, t.slice(0, 400));
  }
}
``` ^ref-d527c05d-209-0

--- ^ref-d527c05d-211-0

# `infra/crawler-js/src/ua.json`

Small list keeps it simple (rotate per request). Add your own.

```json
^ref-d527c05d-211-0
[
  "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
  "Mozilla/5.0 (X11; Linux x86_64; rv:125.0) Gecko/20100101 Firefox/125.0",
  "Mozilla/5.0 (X11; Fedora; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122 Safari/537.36"
]
```
^ref-d527c05d-223-0

---

# `infra/crawler-js/src/crawl.js`

```js
import { PlaywrightCrawler, KeyValueStore, Dataset, log, Configuration } from 'crawlee';
import fs from 'node:fs';
import path from 'node:path';
import { Agent as HttpProxyAgent } from 'node:http';
import { Agent as HttpsProxyAgent } from 'node:https';
import { XMLParser } from 'fast-xml-parser';
import fetch from 'node-fetch';
import uaPool from './ua.json' assert { type: 'json' };
import { sleep, compileRegexList, normalizeUrlForDedup, buildRobotsForOrigin, decideUrl } from './utils.js';
import { sinkToOpenSearch, sinkToMeili } from './sinks.js';

const seed = process.env.CRAWL_SEED || 'https://example.org';
const maxPages = +process.env.CRAWL_MAX_PAGES || 200;
const concurrency = +process.env.CRAWL_CONCURRENCY || 6;
const rpm = +process.env.CRAWL_REQS_PER_MIN || 120;
const respectRobots = String(process.env.RESPECT_ROBOTS || 'true') === 'true';
const sameDomainOnly = String(process.env.SAME_DOMAIN_ONLY || 'true') === 'true';
const allow = compileRegexList(process.env.ALLOW_LIST || '');
const deny = compileRegexList(process.env.DENY_LIST || '');
const outputDir = process.env.OUTPUT_DIR || '/data';
const sitemapDiscover = String(process.env.SITEMAP_DISCOVER || 'true') === 'true';
const rssDiscover = String(process.env.RSS_DISCOVER || 'true') === 'true';
const dedupNormalize = String(process.env.DEDUP_NORMALIZE || 'true') === 'true';

const OS_URL = process.env.SINK_OPENSEARCH_URL || '';
const OS_INDEX = process.env.SINK_OPENSEARCH_INDEX || 'documents';
const MEILI_URL = process.env.SINK_MEILI_URL || '';
const MEILI_KEY = process.env.SINK_MEILI_KEY || '';
const MEILI_INDEX = process.env.SINK_MEILI_INDEX || 'documents';

fs.mkdirSync(outputDir, { recursive: true });
const outPath = path.join(outputDir, 'out.jsonl');
const appendJSONL = (o) => fs.appendFileSync(outPath, JSON.stringify(o) + '\n');

const seedUrl = new URL(seed);
const seedOrigin = seedUrl.origin;

const proxyUrl = process.env.PROXY_URL || '';
const httpAgent = proxyUrl ? new HttpProxyAgent(proxyUrl) : undefined;
const httpsAgent = proxyUrl ? new HttpsProxyAgent(proxyUrl) : undefined;

let robotsByOrigin = {};

async function maybeRobots(url) {
  const origin = new URL(url).origin;
  if (!respectRobots) return { isAllowed: () => true };
  if (!robotsByOrigin[origin]) robotsByOrigin[origin] = await buildRobotsForOrigin(origin, url.startsWith('https') ? httpsAgent : httpAgent);
  return robotsByOrigin[origin];
}

async function discoverSitemaps(origin) {
  if (!sitemapDiscover) return [];
  try {
    const res = await fetch(`${origin}/sitemap.xml`, { agent: origin.startsWith('https') ? httpsAgent : httpAgent, timeout: 10000 });
    if (!res.ok) return [];
    const xml = await res.text();
    const parser = new XMLParser({ ignoreAttributes: false });
    const j = parser.parse(xml);
    const urls = [];
    if (j.urlset?.url) {
      const arr = Array.isArray(j.urlset.url) ? j.urlset.url : [j.urlset.url];
      for (const u of arr) if (u.loc) urls.push(u.loc);
    }
    if (j.sitemapindex?.sitemap) {
      const arr = Array.isArray(j.sitemapindex.sitemap) ? j.sitemapindex.sitemap : [j.sitemapindex.sitemap];
      for (const sm of arr) if (sm.loc) urls.push(sm.loc);
    }
    return urls;
  } catch { return []; }
}

async function discoverRSS(origin) {
  if (!rssDiscover) return [];
  try {
    const res = await fetch(origin, { agent: origin.startsWith('https') ? httpsAgent : httpAgent, timeout: 10000 });
    if (!res.ok) return [];
    const html = await res.text();
    const matches = [...html.matchAll(/<link[^>]+type=['"]application\/(rss\+xml|atom\+xml)['"][^>]*>/gi)];
    const urls = [];
    for (const m of matches) {
      const href = (m[0].match(/href=['"]([^'"]+)['"]/i) || [])[1];
      if (href) urls.push(new URL(href, origin).toString());
    }
    return urls;
  } catch { return []; }
}

function rotateUA(i) {
  return uaPool[i % uaPool.length] || uaPool[0];
}

Configuration.set({ persistStorage: true, storageDir: './storage' });

const crawler = new PlaywrightCrawler({
  maxRequestsPerCrawl: maxPages,
  maxConcurrency: concurrency,
  maxRequestsPerMinute: rpm,
  headless: true,
  requestHandlerTimeoutSecs: 60,
  launchContext: { launchOptions: { args: ['--no-sandbox', '--disable-dev-shm-usage'] } },
  async preNavigationHooks([{ request, session }, gotoOptions]) {
    // robots + allow/deny checks
    const urlToFetch = dedupNormalize ? normalizeUrlForDedup(request.url) : request.url;
    if (!decideUrl(urlToFetch, { sameDomainOnly, seedOrigin, allow, deny })) {
      request.noRetry = true; throw new Error('Filtered: allow/deny or cross-domain');
    }
    const rb = await maybeRobots(urlToFetch);
    if (!rb.isAllowed(urlToFetch, 'PrometheanCrawler')) {
      request.noRetry = true; throw new Error('Robots disallow');
    }
    // polite headers
    request.headers ??= {};
    request.headers['User-Agent'] = rotateUA(session?.id ? parseInt(session.id, 10) : Math.floor(Math.random() * 1000));
    request.headers['Accept-Language'] = 'en-US,en;q=0.9';
    if (proxyUrl) gotoOptions.proxy = { server: proxyUrl };
    gotoOptions.waitUntil = 'domcontentloaded';
  },
  async requestHandler({ request, page, enqueueLinks }) {
    const url = dedupNormalize ? normalizeUrlForDedup(request.url) : request.url;

    // content capture
    const title = await page.title().catch(()=>'');
    const content = await page.content().catch(()=>'');
    const now = new Date().toISOString();

    const doc = { url, title, content, fetched_at: now };

    appendJSONL(doc);
    await Dataset.pushData(doc);

    // Optional sinks (batch every N items in real life)
    await sinkToOpenSearch([doc], { url: OS_URL, index: OS_INDEX });
    await sinkToMeili([doc], { url: MEILI_URL, index: MEILI_INDEX, apiKey: MEILI_KEY });

    // enqueue same-domain links (or external if you toggled sameDomainOnly=false + allow rules)
    await enqueueLinks({
      strategy: sameDomainOnly ? 'same-domain' : 'all',
      transformRequestFunction: (req) => {
        req.url = dedupNormalize ? normalizeUrlForDedup(req.url) : req.url;
        return req;
      }
    });
  },
  async failedRequestHandler({ request, error }) {
    appendJSONL({ url: request.url, error: String(error), failed_at: new Date().toISOString() });
  }
});

// bootstrap queue with seed + sitemaps + rss
const rq = await KeyValueStore.open();
await rq.setValue('__meta__', { seed, started_at: new Date().toISOString() });

const initialUrls = new Set([seed]);
^ref-d527c05d-223-0
if (sitemapDiscover) for (const u of await discoverSitemaps(seedOrigin)) initialUrls.add(u);
if (rssDiscover) for (const u of await discoverRSS(seedOrigin)) initialUrls.add(u);

log.setLevel(log.LEVELS.INFO);
await crawler.run([...initialUrls]);
console.log(`JSONL: ${outPath}`);
^ref-d527c05d-389-0
```
^ref-d527c05d-231-0
^ref-d527c05d-389-0

---

# Run it
 ^ref-d527c05d-400-0
```bash
# bring up the proxy (optional) + crawler
docker compose --profile crawl-js up --build crawler-js

^ref-d527c05d-389-0
# tweak via env (examples) ^ref-d527c05d-402-0
CRAWL_SEED=https://news.ycombinator.com \
ALLOW_LIST="^https://news.ycombinator.com/,^https://ycombinator\.com/" \ ^ref-d527c05d-404-0
CRAWL_MAX_PAGES=500 \
CRAWL_CONCURRENCY=8 \
CRAWL_REQS_PER_MIN=240 \
^ref-d527c05d-404-0
^ref-d527c05d-402-0
docker compose --profile crawl-js up --build crawler-js ^ref-d527c05d-412-0
^ref-d527c05d-413-0 ^ref-d527c05d-414-0
^ref-d527c05d-412-0 ^ref-d527c05d-415-0
^ref-d527c05d-404-0 ^ref-d527c05d-416-0
^ref-d527c05d-402-0 ^ref-d527c05d-417-0
^ref-d527c05d-400-0
``` ^ref-d527c05d-413-0
^ref-d527c05d-401-0
^ref-d527c05d-413-0 ^ref-d527c05d-419-0
^ref-d527c05d-412-0
^ref-d527c05d-404-0 ^ref-d527c05d-421-0
^ref-d527c05d-402-0
^ref-d527c05d-400-0
 ^ref-d527c05d-414-0 ^ref-d527c05d-419-0
**Outputs** ^ref-d527c05d-415-0
 ^ref-d527c05d-412-0 ^ref-d527c05d-416-0 ^ref-d527c05d-421-0
* JSONL at `./crawl_data/out.jsonl` (volume) ^ref-d527c05d-413-0 ^ref-d527c05d-417-0
* Crawlee persistent storage (queue/dataset) at `./crawl_storage/` for resumability ^ref-d527c05d-414-0
 ^ref-d527c05d-415-0 ^ref-d527c05d-419-0
--- ^ref-d527c05d-416-0
 ^ref-d527c05d-417-0 ^ref-d527c05d-421-0
## Why this is solid (and stays JS) ^ref-d527c05d-432-0
 ^ref-d527c05d-419-0 ^ref-d527c05d-433-0
* Playwright + Crawlee = fast, headless, resilient, tested.
* Robots.txt respected, **allow/deny** regex gates, **same-domain** toggle. ^ref-d527c05d-421-0
* **UA rotation**, **rate limiting** (RPM), **concurrency** caps. ^ref-d527c05d-436-0
* **Dedup normalization** avoids re-crawling tracker variants. ^ref-d527c05d-432-0
* **Sitemap + RSS discovery** to fan out intelligently. ^ref-d527c05d-433-0
* **Local sinks** only (Meili/OpenSearch) — no external calls.
* Fully reproducible in Docker; no Python creep.
 ^ref-d527c05d-436-0 ^ref-d527c05d-441-0
Want me to add a **simple DOM extractor** (meta tags, visible text, main article heuristics) or a **per-domain config file** so you can override throttles/parsers without changing code? I can drop both in quickly. ^ref-d527c05d-432-0
 ^ref-d527c05d-433-0
\#webcrawling #javascript #playwright #crawlee #docker #airgapped #selfhosted #meilisearch #opensearch #obsidian<!-- GENERATED-SECTIONS:DO-NOT-EDIT-BELOW -->
## Related content
- [Per-Domain Policy System for JS Crawler](per-domain-policy-system-for-js-crawler.md)
- [Vectorial Exception Descent](vectorial-exception-descent.md)
- [WebSocket Gateway Implementation](websocket-gateway-implementation.md)
- [i3-config-validation-methods](i3-config-validation-methods.md)
- [Model Selection for Lightweight Conversational Tasks](model-selection-for-lightweight-conversational-tasks.md)
- [sibilant-metacompiler-overview](sibilant-metacompiler-overview.md)
- [State Snapshots API and Transactional Projector](state-snapshots-api-and-transactional-projector.md)
- [Pipeline Enhancements](pipeline-enhancements.md)
- [Interop and Source Maps](interop-and-source-maps.md)
- [Post-Linguistic Transhuman Design Frameworks](post-linguistic-transhuman-design-frameworks.md)
- [promethean-system-diagrams](promethean-system-diagrams.md)
- [Universal Lisp Interface](universal-lisp-interface.md)
- [Matplotlib Animation with Async Execution](matplotlib-animation-with-async-execution.md)
- [RAG UI Panel with Qdrant and PostgREST](rag-ui-panel-with-qdrant-and-postgrest.md)
- [mystery-lisp-search-session](mystery-lisp-search-session.md)
- [komorebi-group-window-hack](komorebi-group-window-hack.md)
- [Promethean-native config design](promethean-native-config-design.md)
- [universal-intention-code-fabric](universal-intention-code-fabric.md)
- [compiler-kit-foundations](compiler-kit-foundations.md)
- [Exception Layer Analysis](exception-layer-analysis.md)
- [SentenceProcessing](sentenceprocessing.md)
- [Language-Agnostic Mirror System](language-agnostic-mirror-system.md)
- [Sibilant Meta-Prompt DSL](sibilant-meta-prompt-dsl.md)
- [Event Bus MVP](event-bus-mvp.md)
- [Cross-Language Runtime Polymorphism](cross-language-runtime-polymorphism.md)
- [js-to-lisp-reverse-compiler](js-to-lisp-reverse-compiler.md)
- [ecs-scheduler-and-prefabs](ecs-scheduler-and-prefabs.md)
- [Chroma Toolkit Consolidation Plan](chroma-toolkit-consolidation-plan.md)
- [Polyglot S-expr Bridge: Python-JS-Lisp Interop](polyglot-s-expr-bridge-python-js-lisp-interop.md)
- [Lisp-Compiler-Integration](lisp-compiler-integration.md)
- [shared-package-layout-clarification](shared-package-layout-clarification.md)
- [Promethean Web UI Setup](promethean-web-ui-setup.md)
- [Promethean Full-Stack Docker Setup](promethean-full-stack-docker-setup.md)
- [Promethean Pipelines: Local TypeScript-First Workflow](promethean-pipelines-local-typescript-first-workflow.md)
- [Migrate to Provider-Tenant Architecture](migrate-to-provider-tenant-architecture.md)
- [refactor-relations](refactor-relations.md)
- [Refactor 05-footers.ts](refactor-05-footers-ts.md)
- [ecs-offload-workers](ecs-offload-workers.md)
- [Local-Offline-Model-Deployment-Strategy](local-offline-model-deployment-strategy.md)
- [set-assignment-in-lisp-ast](set-assignment-in-lisp-ast.md)
- [Pure TypeScript Search Microservice](pure-typescript-search-microservice.md)
- [Promethean Event Bus MVP v0.1](promethean-event-bus-mvp-v0-1.md)
- [Recursive Prompt Construction Engine](recursive-prompt-construction-engine.md)
- [Chroma-Embedding-Refactor](chroma-embedding-refactor.md)
- [Promethean Agent Config DSL](promethean-agent-config-dsl.md)
- [Shared Package Structure](shared-package-structure.md)
- [observability-infrastructure-setup](observability-infrastructure-setup.md)
- [prom-lib-rate-limiters-and-replay-api](prom-lib-rate-limiters-and-replay-api.md)
- [Mongo Outbox Implementation](mongo-outbox-implementation.md)
- [markdown-to-org-transpiler](markdown-to-org-transpiler.md)
- [polyglot-repl-interface-layer](polyglot-repl-interface-layer.md)
- [Promethean Agent DSL TS Scaffold](promethean-agent-dsl-ts-scaffold.md)
- [Local-First Intention→Code Loop with Free Models](local-first-intention-code-loop-with-free-models.md)
- [Event Bus Projections Architecture](event-bus-projections-architecture.md)
- [heartbeat-fragment-demo](heartbeat-fragment-demo.md)
- [Local-Only-LLM-Workflow](local-only-llm-workflow.md)
- [balanced-bst](balanced-bst.md)
- [Promethean Notes](promethean-notes.md)
- [i3-bluetooth-setup](i3-bluetooth-setup.md)
- [field-dynamics-math-blocks](field-dynamics-math-blocks.md)
- [eidolon-field-math-foundations](eidolon-field-math-foundations.md)
- [field-node-diagram-set](field-node-diagram-set.md)
- [homeostasis-decay-formulas](homeostasis-decay-formulas.md)
- [Ice Box Reorganization](ice-box-reorganization.md)
- [file-watcher-auth-fix](file-watcher-auth-fix.md)
- [Promethean Infrastructure Setup](promethean-infrastructure-setup.md)
- [Prometheus Observability Stack](prometheus-observability-stack.md)
- [Dynamic Context Model for Web Components](dynamic-context-model-for-web-components.md)
- [Promethean_Eidolon_Synchronicity_Model](promethean-eidolon-synchronicity-model.md)
- [sibilant-macro-targets](sibilant-macro-targets.md)
- [Ghostly Smoke Interference](ghostly-smoke-interference.md)
- [ripple-propagation-demo](ripple-propagation-demo.md)
- [System Scheduler with Resource-Aware DAG](system-scheduler-with-resource-aware-dag.md)
- [Ollama-LLM-Provider-for-Pseudo-Code-Transpiler](ollama-llm-provider-for-pseudo-code-transpiler.md)
## Sources
- [Model Selection for Lightweight Conversational Tasks — L103](model-selection-for-lightweight-conversational-tasks.md#^ref-d144aa62-103-0) (line 103, col 0, score 0.87)
- [Universal Lisp Interface — L137](universal-lisp-interface.md#^ref-b01856b4-137-0) (line 137, col 0, score 0.86)
- [komorebi-group-window-hack — L132](komorebi-group-window-hack.md#^ref-dd89372d-132-0) (line 132, col 0, score 0.85)
- [Per-Domain Policy System for JS Crawler — L188](per-domain-policy-system-for-js-crawler.md#^ref-c03020e1-188-0) (line 188, col 0, score 0.88)
- [compiler-kit-foundations — L590](compiler-kit-foundations.md#^ref-01b21543-590-0) (line 590, col 0, score 0.85)
- [Vectorial Exception Descent — L95](vectorial-exception-descent.md#^ref-d771154e-95-0) (line 95, col 0, score 0.89)
- [WebSocket Gateway Implementation — L631](websocket-gateway-implementation.md#^ref-e811123d-631-0) (line 631, col 0, score 0.88)
- [sibilant-metacompiler-overview — L52](sibilant-metacompiler-overview.md#^ref-61d4086b-52-0) (line 52, col 0, score 0.87)
- [State Snapshots API and Transactional Projector — L303](state-snapshots-api-and-transactional-projector.md#^ref-509e1cd5-303-0) (line 303, col 0, score 0.87)
- [promethean-system-diagrams — L169](promethean-system-diagrams.md#^ref-b51e19b4-169-0) (line 169, col 0, score 0.85)
- [Matplotlib Animation with Async Execution — L16](matplotlib-animation-with-async-execution.md#^ref-687439f9-16-0) (line 16, col 0, score 0.86)
- [mystery-lisp-search-session — L106](mystery-lisp-search-session.md#^ref-513dc4c7-106-0) (line 106, col 0, score 0.85)
- [universal-intention-code-fabric — L388](universal-intention-code-fabric.md#^ref-c14edce7-388-0) (line 388, col 0, score 0.85)
- [Pipeline Enhancements — L169](pipeline-enhancements.md#^ref-e2135d9f-169-0) (line 169, col 0, score 0.87)
- [Post-Linguistic Transhuman Design Frameworks — L269](post-linguistic-transhuman-design-frameworks.md#^ref-6bcff92c-269-0) (line 269, col 0, score 0.86)
- [RAG UI Panel with Qdrant and PostgREST — L349](rag-ui-panel-with-qdrant-and-postgrest.md#^ref-e1056831-349-0) (line 349, col 0, score 0.85)
- [Promethean-native config design — L305](promethean-native-config-design.md#^ref-ab748541-305-0) (line 305, col 0, score 0.85)
- [i3-config-validation-methods — L28](i3-config-validation-methods.md#^ref-d28090ac-28-0) (line 28, col 0, score 0.87)
- [Interop and Source Maps — L498](interop-and-source-maps.md#^ref-cdfac40c-498-0) (line 498, col 0, score 0.87)
<!-- GENERATED-SECTIONS:DO-NOT-EDIT-ABOVE -->
