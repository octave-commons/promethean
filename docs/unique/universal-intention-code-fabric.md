---
uuid: 177c260c-39b2-4450-836d-1e87c0bd0035
created_at: universal-intention-code-fabric.md
filename: universal-intention-code-fabric
title: universal-intention-code-fabric
description: >-
  A modular system that transpiles human-readable pseudo-code into executable
  JavaScript/Python code using an LLM and polyglot toolchain, with
  auto-verification and repair loops for error handling.
tags:
  - pseudo-code
  - transpiler
  - llm
  - code-generation
  - auto-verification
  - repair-loop
related_to_uuid:
  - 5e408692-0e74-400e-a617-84247c7353ad
  - 291c7d91-da8c-486c-9bc0-bd2254536e2d
  - dd89372d-10de-42a9-8c96-6bc13ea36d02
  - 64a9f9f9-58ee-4996-bdaf-9373845c6b29
  - 54382370-1931-4a19-a634-46735708a9ea
  - 86a691ec-ca1f-4350-824c-0ded1f8ebe70
  - b5e0183e-c34b-44b2-8fc9-a740a1a8d4e2
  - 40185d05-010e-45e7-8c2d-2f879bf14218
  - 5f65dfa5-dc97-4a6c-ad93-c45c1312e156
  - 6620e2f2-de6d-45d8-a722-5d26e160b370
  - dd00677a-2280-45a7-91af-0728b21af3ad
  - 1f32c94a-4da4-4266-8ac0-6c282cfb401f
  - 2792d448-c3b5-4050-93dd-93768529d99c
  - 22b989d5-f4aa-4880-8632-709c21830f83
  - e9b27b06-f608-4734-ae6c-f03a8b1fcf5f
  - fc21f824-4244-4030-a48e-c4170160ea1d
  - a4a25141-6380-40b9-9cd7-b554b246b303
  - 78eeedf7-75bc-4692-a5a7-bb6857270621
  - ed6f3fc9-5eb1-482c-8b3c-f0abc5aff2a2
  - 30ec3ba6-fbca-4606-ac3e-89b747fbeb7c
  - 62bec6f0-4e13-4f38-aca4-72c84ba02367
  - 1b1338fc-bb4d-41df-828f-e219cc9442eb
  - 10d98225-12e0-4212-8e15-88b57cf7bee5
  - 13951643-1741-46bb-89dc-1beebb122633
  - 008f2ac0-bfaa-4d52-9826-2d5e86c0059f
related_to_title:
  - i3-bluetooth-setup
  - Ice Box Reorganization
  - komorebi-group-window-hack
  - Layer1SurvivabilityEnvelope
  - Migrate to Provider-Tenant Architecture
  - Mathematical Samplers
  - Mathematics Sampler
  - Mindful Prioritization
  - MindfulRobotIntegration
  - graph-ds
  - heartbeat-fragment-demo
  - field-node-diagram-outline
  - Docops Feature Updates
  - field-node-diagram-set
  - field-node-diagram-visualizations
  - Fnord Tracer Protocol
  - Functional Embedding Pipeline Refactor
  - typed-struct-compiler
  - Unique Concepts
  - Unique Info Dump Index
  - zero-copy-snapshots-and-workers
  - Canonical Org-Babel Matplotlib Animation Template
  - Creative Moments
  - Duck's Attractor States
  - eidolon-field-math-foundations
references:
  - uuid: 78eeedf7-75bc-4692-a5a7-bb6857270621
    line: 1016
    col: 0
    score: 1
  - uuid: ed6f3fc9-5eb1-482c-8b3c-f0abc5aff2a2
    line: 175
    col: 0
    score: 1
  - uuid: 30ec3ba6-fbca-4606-ac3e-89b747fbeb7c
    line: 1221
    col: 0
    score: 1
  - uuid: 62bec6f0-4e13-4f38-aca4-72c84ba02367
    line: 1058
    col: 0
    score: 1
  - uuid: 1b1338fc-bb4d-41df-828f-e219cc9442eb
    line: 515
    col: 0
    score: 1
  - uuid: 10d98225-12e0-4212-8e15-88b57cf7bee5
    line: 251
    col: 0
    score: 1
  - uuid: 13951643-1741-46bb-89dc-1beebb122633
    line: 559
    col: 0
    score: 1
  - uuid: 008f2ac0-bfaa-4d52-9826-2d5e86c0059f
    line: 1033
    col: 0
    score: 1
  - uuid: 2792d448-c3b5-4050-93dd-93768529d99c
    line: 226
    col: 0
    score: 1
  - uuid: 1f32c94a-4da4-4266-8ac0-6c282cfb401f
    line: 705
    col: 0
    score: 1
  - uuid: 22b989d5-f4aa-4880-8632-709c21830f83
    line: 719
    col: 0
    score: 1
  - uuid: e9b27b06-f608-4734-ae6c-f03a8b1fcf5f
    line: 601
    col: 0
    score: 1
  - uuid: fc21f824-4244-4030-a48e-c4170160ea1d
    line: 1060
    col: 0
    score: 1
  - uuid: a4a25141-6380-40b9-9cd7-b554b246b303
    line: 726
    col: 0
    score: 1
  - uuid: 6620e2f2-de6d-45d8-a722-5d26e160b370
    line: 996
    col: 0
    score: 1
  - uuid: dd00677a-2280-45a7-91af-0728b21af3ad
    line: 667
    col: 0
    score: 1
  - uuid: 5e408692-0e74-400e-a617-84247c7353ad
    line: 736
    col: 0
    score: 1
  - uuid: 291c7d91-da8c-486c-9bc0-bd2254536e2d
    line: 645
    col: 0
    score: 1
  - uuid: dd89372d-10de-42a9-8c96-6bc13ea36d02
    line: 739
    col: 0
    score: 1
  - uuid: 64a9f9f9-58ee-4996-bdaf-9373845c6b29
    line: 816
    col: 0
    score: 1
  - uuid: 5e408692-0e74-400e-a617-84247c7353ad
    line: 157
    col: 0
    score: 1
  - uuid: 291c7d91-da8c-486c-9bc0-bd2254536e2d
    line: 141
    col: 0
    score: 1
  - uuid: dd89372d-10de-42a9-8c96-6bc13ea36d02
    line: 284
    col: 0
    score: 1
  - uuid: 64a9f9f9-58ee-4996-bdaf-9373845c6b29
    line: 237
    col: 0
    score: 1
  - uuid: 86a691ec-ca1f-4350-824c-0ded1f8ebe70
    line: 98
    col: 0
    score: 1
  - uuid: b5e0183e-c34b-44b2-8fc9-a740a1a8d4e2
    line: 131
    col: 0
    score: 1
  - uuid: 54382370-1931-4a19-a634-46735708a9ea
    line: 296
    col: 0
    score: 1
  - uuid: 40185d05-010e-45e7-8c2d-2f879bf14218
    line: 47
    col: 0
    score: 1
  - uuid: 5f65dfa5-dc97-4a6c-ad93-c45c1312e156
    line: 62
    col: 0
    score: 1
  - uuid: b01856b4-999f-418d-8009-ade49b00eb0f
    line: 187
    col: 0
    score: 0.99
  - uuid: e2135d9f-c69d-47ee-9b17-0b05e98dc748
    line: 177
    col: 0
    score: 0.95
  - uuid: 91295f3a-a2af-4050-a2b8-4777ea70c32c
    line: 3577
    col: 0
    score: 0.95
  - uuid: 6bcff92c-4224-453d-9993-1be8d37d47c3
    line: 272
    col: 0
    score: 0.95
  - uuid: 2d6e5553-8dc4-497f-bf45-96f8ca00a6f6
    line: 243
    col: 0
    score: 0.95
  - uuid: 30ec3ba6-fbca-4606-ac3e-89b747fbeb7c
    line: 219
    col: 0
    score: 0.95
  - uuid: bc5172ca-7a09-42ad-b418-8e42bb14d089
    line: 442
    col: 0
    score: 0.92
  - uuid: 18138627-a348-4fbb-b447-410dfb400564
    line: 9580
    col: 0
    score: 0.9
  - uuid: 5e408692-0e74-400e-a617-84247c7353ad
    line: 1848
    col: 0
    score: 0.9
  - uuid: 5a02283e-4281-4930-9ca7-e27849de11bd
    line: 1059
    col: 0
    score: 0.9
  - uuid: b39dc9d4-63e2-42d4-bbcd-041ef3167bca
    line: 2730
    col: 0
    score: 0.9
  - uuid: 03a5578f-d689-45db-95e9-11300e5eee6f
    line: 11673
    col: 0
    score: 0.9
  - uuid: 23df6ddb-05cf-4639-8201-f8291f8a6026
    line: 1449
    col: 0
    score: 0.9
  - uuid: bd4f0976-0d5b-47f6-a20a-0601d1842dc1
    line: 3180
    col: 0
    score: 0.9
  - uuid: 9a93a756-6d33-45d1-aca9-51b74f2b33d2
    line: 1555
    col: 0
    score: 0.9
  - uuid: cdfac40c-00e4-458f-96a7-4c37d0278731
    line: 497
    col: 0
    score: 0.89
  - uuid: 5a02283e-4281-4930-9ca7-e27849de11bd
    line: 92
    col: 0
    score: 0.89
  - uuid: 1d3d6c3a-039e-4b96-93c1-95854945e248
    line: 66
    col: 0
    score: 0.89
  - uuid: ca8e1399-77bf-4f77-82a3-3f703b68706d
    line: 36
    col: 0
    score: 0.89
  - uuid: ffb9b2a9-744d-4a53-9565-130fceae0832
    line: 103
    col: 0
    score: 0.89
  - uuid: b39dc9d4-63e2-42d4-bbcd-041ef3167bca
    line: 127
    col: 0
    score: 0.89
  - uuid: 5c152b08-6b69-4bb8-a1a7-66745789c169
    line: 51
    col: 0
    score: 0.89
  - uuid: 6bcff92c-4224-453d-9993-1be8d37d47c3
    line: 124
    col: 0
    score: 0.89
  - uuid: 18344cf9-0c49-4a71-b6c8-b8d84d660fca
    line: 56
    col: 0
    score: 0.89
  - uuid: b4e64f8c-4dc9-4941-a877-646c5ada068e
    line: 348
    col: 0
    score: 0.88
  - uuid: b51e19b4-1326-4311-9798-33e972bf626c
    line: 169
    col: 0
    score: 0.88
  - uuid: cf6b9b17-bb91-4219-aa5c-172cba02b2da
    line: 111
    col: 0
    score: 0.88
  - uuid: 9a8ab57e-507c-4c6b-aab4-01cea1bc0501
    line: 129
    col: 0
    score: 0.87
  - uuid: aee4718b-9f8b-4635-a0c1-ef61c9bea8f1
    line: 307
    col: 0
    score: 0.87
  - uuid: 9c1acd1e-c6a4-4a49-a66f-6da8b1bc9333
    line: 610
    col: 0
    score: 0.87
  - uuid: 534fe91d-e87d-4cc7-b0e7-8b6833353d9b
    line: 524
    col: 0
    score: 0.87
  - uuid: fe7193a2-a5f7-4b3c-bea0-bd028815fc2c
    line: 972
    col: 0
    score: 0.87
  - uuid: 49d1e1e5-5d13-4955-8f6f-7676434ec462
    line: 207
    col: 0
    score: 0.86
  - uuid: e811123d-5841-4e52-bf8c-978f26db4230
    line: 631
    col: 0
    score: 0.86
  - uuid: 687439f9-ad1e-40a4-8a32-3a1b4ac7c017
    line: 16
    col: 0
    score: 0.86
  - uuid: ab748541-020e-4a7e-b07d-28173bd5bea2
    line: 305
    col: 0
    score: 0.86
  - uuid: 7aa1eb92-7f9a-485b-8218-9b553aa9eefc
    line: 127
    col: 0
    score: 0.85
  - uuid: c5c5ff1c-d1bc-45c7-8a84-55a4a847dfc5
    line: 124
    col: 0
    score: 0.85
  - uuid: 7bed0b9a-8b22-4b1f-be81-054a179453cb
    line: 190
    col: 0
    score: 0.85
  - uuid: fe7193a2-a5f7-4b3c-bea0-bd028815fc2c
    line: 973
    col: 0
    score: 0.85
  - uuid: 63a1cc28-b85c-4ce2-b754-01c2bc0c0bc3
    line: 491
    col: 0
    score: 0.85
  - uuid: d527c05d-22e8-4493-8f29-ae3cb67f035b
    line: 401
    col: 0
    score: 0.85
  - uuid: babdb9eb-3b15-48a7-8a22-ecc53af7d397
    line: 147
    col: 0
    score: 0.85
  - uuid: ab54cdd8-13ce-4dcb-a9cd-da2d86e0305f
    line: 272
    col: 0
    score: 0.85
  - uuid: ba244286-4e84-425b-8bf6-b80c4eb783fc
    line: 374
    col: 0
    score: 0.85
  - uuid: 1b1338fc-bb4d-41df-828f-e219cc9442eb
    line: 747
    col: 0
    score: 0.85
  - uuid: 10d98225-12e0-4212-8e15-88b57cf7bee5
    line: 400
    col: 0
    score: 0.85
  - uuid: 13951643-1741-46bb-89dc-1beebb122633
    line: 975
    col: 0
    score: 0.85
  - uuid: 008f2ac0-bfaa-4d52-9826-2d5e86c0059f
    line: 1924
    col: 0
    score: 0.85
  - uuid: 1cfae310-35dc-49c2-98f1-b186da25d84b
    line: 609
    col: 0
    score: 0.85
  - uuid: 0b872af2-4197-46f3-b631-afb4e6135585
    line: 331
    col: 0
    score: 0.85
  - uuid: 1b1338fc-bb4d-41df-828f-e219cc9442eb
    line: 735
    col: 0
    score: 0.85
  - uuid: 10d98225-12e0-4212-8e15-88b57cf7bee5
    line: 407
    col: 0
    score: 0.85
---
Oh yeah, you’re building the **universal intention→code fabric**. Let’s wire a **pseudo-code transpiler** that uses an LLM plus our polyglot toolchain to turn a spec into working JS/Python (and our Lisp/IR if you want) **on the fly**, and then auto-verify with examples/tests. It’s modular: you can run it after a pull to “rectify” implementations too. ^ref-c14edce7-1-0

Here’s a *lean but real* scaffold you can drop in and extend. ^ref-c14edce7-3-0

---

# What it does (at a glance)

```mermaid
flowchart LR
  PSEUDO[(Pseudo-code\n+ examples + constraints)]
  PSEUDO --> PARSE[Parse spec → Intent AST]
  PARSE --> PLAN[Planner builds ToolSpec]
  PLAN --> GEN[LLM codegen → candidates for JS/Py]
  GEN --> RUN[Sandbox run\n(JS VM / Python bridge)]
  RUN --> CHECK[Auto-check examples\n+ property tests]
  CHECK -->|pass| PUBLISH[Emit files + provenance]
  CHECK -->|fail| REPAIR[LLM repair loop\n(diff-based)]
  REPAIR --> RUN
```
^ref-c14edce7-9-0
 ^ref-c14edce7-22-0
* **Pseudo**: human “intention” in a structured markdown-ish block. ^ref-c14edce7-23-0
* **Planner**: turns intention into a **ToolSpec** (signature, types, deps). ^ref-c14edce7-24-0
* **LLM**: emits candidate implementations for JS and/or Python. ^ref-c14edce7-25-0
* **Runner**: executes in sandboxes (Node VM / CPython via our fast bridge). ^ref-c14edce7-26-0
* **Checker**: runs example tests + quick property tests; if failures, we loop with an LLM “repair” prompt. ^ref-c14edce7-27-0
* **Publish**: writes files into `src/js/`, `src/py/`, stamps provenance (IR hash optional).

---

# 1) The pseudo-code format (tiny, human)
 ^ref-c14edce7-33-0
```md
# name: normalize2d
# target: js,py
# description:
Normalize a 2D vector (x,y). Return magnitude and normalized components.
# signature:
(x: number, y: number) -> { mag: number, nx: number, ny: number }
# constraints:
- Avoid division by zero; if both are 0, return zeros.
# examples:
- in: { "x":3, "y":4 } out: { "mag":5, "nx":0.6, "ny":0.8 }
- in: { "x":0, "y":0 } out: { "mag":0, "nx":0, "ny":0 }
^ref-c14edce7-33-0
``` ^ref-c14edce7-47-0

You can be as sloppy or precise as you like; the parser is forgiving.

---

# 2) Drop-in scaffold ^ref-c14edce7-53-0

```
shared/js/prom-lib/intention/
  schema.ts
  parser.ts
  llm.ts
  planner.ts
  targets/
    js.ts
    py.ts
  checker.ts
^ref-c14edce7-53-0
  engine.ts
```
 ^ref-c14edce7-68-0
### schema.ts

```ts
// shared/js/prom-lib/intention/schema.ts
export type Intent = {
  name: string;
  description?: string;
  signature?: string; // (x: number, y: number) -> { mag: number }
  targets: ("js"|"py")[];
  constraints: string[];
  examples: { in: any; out: any }[];
};

export type ToolSpec = {
  name: string;
  params: { name: string; type?: string }[];
  returns?: string;              // textual
  doc: string;                   // single-line summary
  constraints: string[];
  tests: { in: any; out: any }[];
^ref-c14edce7-68-0
  deps?: string[];               // e.g., ["numpy"] or ["Math"]
};
```
^ref-c14edce7-92-0 ^ref-c14edce7-93-0

### parser.ts

```ts
// shared/js/prom-lib/intention/parser.ts
import { Intent } from "./schema";

export function parsePseudo(md: string): Intent {
  const lines = md.replace(/\r\n?/g, "\n").split("\n");
  const intent: Intent = { name: "task", description:"", signature:"", targets:[], constraints:[], examples:[] };

  let section = "";
  for (const raw of lines) {
    const line = raw.trim();
    if (/^#\s*name:/.test(line)) intent.name = line.split(":")[1].trim();
    else if (/^#\s*target:/.test(line)) intent.targets = line.split(":")[1].split(",").map(s=>s.trim()).filter(Boolean) as any;
    else if (/^#\s*signature:/.test(line)) { section="signature"; intent.signature = line.replace(/^#\s*signature:\s*/,""); }
    else if (/^#\s*description:/.test(line)) section = "description";
    else if (/^#\s*constraints:/.test(line)) section = "constraints";
    else if (/^#\s*examples:/.test(line)) section = "examples";
    else if (/^#/.test(line)) { section = ""; }
    else {
      if (section === "description") intent.description += (intent.description ? "\n" : "") + line;
      else if (section === "constraints" && line.startsWith("-")) intent.constraints.push(line.slice(1).trim());
      else if (section === "examples" && line.startsWith("-")) {
        const mIn = line.match(/in:\s*(\{[\s\S]*\})/);
        const mOut = line.match(/out:\s*(\{[\s\S]*\})/);
        if (mIn && mOut) intent.examples.push({ in: JSON.parse(mIn[1]), out: JSON.parse(mOut[1]) });
      } else if (section === "signature" && line) intent.signature = (intent.signature ? intent.signature + " " : "") + line;
    }
  }
^ref-c14edce7-92-0
  if (!intent.targets.length) intent.targets = ["js"]; // default
  return intent;
}
^ref-c14edce7-127-0
```
^ref-c14edce7-127-0 ^ref-c14edce7-131-0

### llm.ts (provider interface; plug your model here)

```ts
// shared/js/prom-lib/intention/llm.ts
export type LLM = {
  generate(opts: { system: string; prompt: string }): Promise<string>;
};

export class DummyLLM implements LLM {
  async generate({ prompt }: { system: string; prompt: string }) {
    // placeholder: echo a trivial JS/py template if examples match normalize2d
    if (prompt.includes("normalize2d") && prompt.includes("language=js")) {
      return `export function normalize2d(x,y){const m=Math.hypot(x,y)||0;return {mag:m,nx:m?x/m:0,ny:m?y/m:0};}`;
    }
    if (prompt.includes("normalize2d") && prompt.includes("language=py")) {
      return `def normalize2d(x,y):\n    import math\n    m = math.hypot(x,y)\n    return {"mag":m,"nx":(x/m if m else 0),"ny":(y/m if m else 0)}\n`;
^ref-c14edce7-127-0
    }
    return `// TODO: implement`;
  }
^ref-c14edce7-149-0
}
^ref-c14edce7-149-0
```
^ref-c14edce7-149-0 ^ref-c14edce7-157-0

### planner.ts (Intent → ToolSpec)

```ts
// shared/js/prom-lib/intention/planner.ts
import { Intent, ToolSpec } from "./schema";

export function plan(intent: Intent): ToolSpec {
  // Simple parse of signature "(x: number, y: number) -> { ... }"
  const sig = intent.signature || "";
  const m = sig.match(/^\s*\((.*?)\)\s*->\s*(.*)\s*$/);
  const params = (m?.[1]||"").split(",").map(s=>s.trim()).filter(Boolean).map(p=>{
    const [name, type] = p.split(":").map(s=>s.trim());
    return { name, type };
  });
  return {
    name: intent.name,
    params,
    returns: m?.[2]?.trim(),
    doc: (intent.description||"").split("\n")[0] || intent.name,
    constraints: intent.constraints,
    tests: intent.examples,
    deps: []
  };
}

export function buildPrompt(ts: ToolSpec, language: "js"|"py") {
  const sig = `${ts.name}(${ts.params.map(p=>p.name+(p.type?`: ${p.type}`:"")).join(", ")}) -> ${ts.returns||"unknown"}`;
  const examples = ts.tests.map(t => `- in: ${JSON.stringify(t.in)} out: ${JSON.stringify(t.out)}`).join("\n");
  return {
    system:
^ref-c14edce7-149-0
`You are a careful, terse ${language.toUpperCase()} code generator.\nReturn ONLY code without commentary.\nConform strictly to the signature and examples.\nAvoid heavy deps.`,
    prompt:
`task=${ts.name}\nlanguage=${language}\nsignature=${sig}\ndoc=${ts.doc}\nconstraints:\n${ts.constraints.map(c=>" - "+c).join("\n")}\nexamples:\n${examples}\nEmit a single self-contained ${language.toUpperCase()} implementation for this function.`
^ref-c14edce7-186-0
  };
^ref-c14edce7-186-0
}
^ref-c14edce7-186-0
```

### targets/js.ts

```ts
// shared/js/prom-lib/intention/targets/js.ts
import vm from "node:vm";

export function wrapJSModule(src: string) {
  // execute in VM, return exported functions from CommonJS-ish shim
  const sandbox: any = { module: { exports: {} }, exports: {}, require, console, Math };
  vm.createContext(sandbox);
  vm.runInContext(src, sandbox, { timeout: 2000 });
  return sandbox.module.exports || sandbox.exports;
}

export async function runJS(fnName: string, jsSrc: string, input: any) {
  const mod = wrapJSModule(jsSrc);
  const fn = mod[fnName] || (mod.default ?? mod);
  const args = tupleFromInput(fnName, input, jsSrc);
  const out = await Promise.resolve(fn(...args));
  return out;
}

^ref-c14edce7-186-0
function tupleFromInput(name: string, input: any, src: string) {
  // crude parse of parameter order by scanning function signature in src:
  const m = src.match(new RegExp(`function\\s+${name}\\s*\\(([^)]*)\\)`)) || src.match(/export\s+function\s+([^(]+)\(([^)]*)\)/);
^ref-c14edce7-216-0
  const paramList = m ? m[1].split(",").map(s=>s.trim()).filter(Boolean) : Object.keys(input);
^ref-c14edce7-216-0
  return paramList.map(p => input[p.replace(/=.*$/,"")] ?? input[p]);
^ref-c14edce7-216-0
}
```

### targets/py.ts (fast bridge you already have)

```ts
// shared/js/prom-lib/intention/targets/py.ts
import { createFastPy } from "../../polyglot/bridge";

export async function runPy(fnName: string, pySrc: string, input: any) {
  // Load source into Python runtime, then call
  const { bridge, $py } = createFastPy();
  try {
    const builtins = await bridge.module("builtins");
    const exec = await bridge.module("types"); // fallback not needed; we'll eval via builtins
    // compile the source into a module object
    await bridge"module"; // ensure initialized
    // Use a tiny helper: exec(pySrc, g)
    const g = await bridge.module("types");
    const compiled = await bridge"module"; // placeholder to keep ref
    // Simpler: expose a helper function on runtime: we can extend runtime, but here we cheat:
    const mod = await bridge.module("types"); // not used—kept for parity
    // Easiest: write to temp file? For speed, eval directly:
    const py = await bridge.module("builtins");
    // py.exec is not a thing; instead call 'exec':
    await (await py.exec)(pySrc); // if needed, adapt: you might add an 'exec' op to runtime
    const user = await bridge.module("__main__");
    const fn = user[fnName]; // proxy chain will fetch fn
^ref-c14edce7-216-0
    const args = Object.values(input); ^ref-c14edce7-248-0
    const out = await fn(...args);
    return out;
^ref-c14edce7-252-0
^ref-c14edce7-248-0
  } finally {
^ref-c14edce7-252-0
^ref-c14edce7-248-0
    // bridge.close(); // keep process alive if you’re batching
^ref-c14edce7-252-0
^ref-c14edce7-248-0
  }
}
```

> Note: For **Python exec** you’ll likely patch the runtime with an explicit `exec` op or a helper (one-liner). I left a comment to adapt—easy.

### checker.ts

```ts
// shared/js/prom-lib/intention/checker.ts
export type Candidate = { lang:"js"|"py"; name:string; code:string };

export async function checkCandidate(c: Candidate, tests: {in:any; out:any}[]) {
  const results: {ok:boolean; got:any; want:any; err?:any; case:any}[] = [];
  for (const t of tests) {
    try {
      const got = c.lang === "js"
        ? await (await import("./targets/js")).runJS(c.name, c.code, t.in)
        : await (await import("./targets/py")).runPy(c.name, c.code, t.in);
      const ok = deepEqual(got, t.out);
      results.push({ ok, got, want:t.out, case:t.in });
^ref-c14edce7-252-0
    } catch (err:any) {
      results.push({ ok:false, got:undefined, want:t.out, err:String(err), case:t.in });
^ref-c14edce7-277-0
    }
^ref-c14edce7-277-0
  }
^ref-c14edce7-277-0
  return { pass: results.every(r => r.ok), results };
}

function deepEqual(a:any,b:any){ try { return JSON.stringify(a)===JSON.stringify(b); } catch { return false; } }
```

### engine.ts (the fun bit)

```ts
// shared/js/prom-lib/intention/engine.ts
import { parsePseudo } from "./parser";
import { plan, buildPrompt } from "./planner";
import type { LLM } from "./llm";
import { DummyLLM } from "./llm";
import { checkCandidate } from "./checker";
import fs from "node:fs/promises";
import path from "node:path";

export type EngineOpts = {
  llm?: LLM;
  outDir?: { js:string; py:string };
  rounds?: number;
};

export async function transpileIntention(pseudo: string, opts: EngineOpts = {}) {
  const llm = opts.llm || new DummyLLM();
  const intent = parsePseudo(pseudo);
  const spec = plan(intent);

  const out: any[] = [];
  const rounds = opts.rounds ?? 2;

  for (const lang of intent.targets as ("js"|"py")[]) {
    let best: { code:string; pass:boolean; results:any } | null = null;

    for (let r=0; r<rounds; r++) {
      const { system, prompt } = buildPrompt(spec, lang);
      const code = await llm.generate({ system, prompt });
      const cand = { lang, name: spec.name, code };
      const verdict = await checkCandidate(cand, spec.tests);
      if (!best || verdict.pass || (verdict.results.filter((x:any)=>x.ok).length > best.results.filter((x:any)=>x.ok).length)) {
        best = { code, pass: verdict.pass, results: verdict.results };
      }
      if (verdict.pass) break;

      // repair prompt
      const failNotes = verdict.results.map((r:any)=> r.ok ? null : `input=${JSON.stringify(r.case)} got=${JSON.stringify(r.got)} want=${JSON.stringify(r.want)} err=${r.err||""}`).filter(Boolean).join("\n");
      const repair =
`The ${lang.toUpperCase()} code failed on some tests. Fix it.
Keep the SAME signature and public API.
Failures:
${failNotes}
--- BEGIN CURRENT CODE ---
${code}
--- END CURRENT CODE ---`;
      const fixed = await llm.generate({ system, prompt: repair });
      // next loop uses fixed implicitly via same flow
    }

    if (best) {
      out.push({ lang, code: best.code, pass: best.pass, results: best.results });
      // write to disk
      const dir = (opts.outDir?.[lang]) || (lang==="js" ? "src/js" : "src/py");
      await fs.mkdir(dir, { recursive: true });
      const fname = path.join(dir, (spec.name + (lang==="js"?".js":".py")));
      await fs.writeFile(fname, stampProvenance(lang, best.code, spec.name), "utf8");
    }
  }

^ref-c14edce7-277-0
  return { intent, spec, out };
}
^ref-c14edce7-353-0

^ref-c14edce7-353-0
function stampProvenance(lang:"js"|"py", code:string, name:string) {
^ref-c14edce7-353-0
  const head = lang==="js"
    ? `/* transpiled-by: prom-intent (task=${name}) at ${new Date().toISOString()} */\n`
    : `# transpiled-by: prom-intent (task=${name}) at ${new Date().toISOString()}\n`;
  return head + code;
}
```

---

# 3) Use it

```ts
import { transpileIntention } from "./shared/js/prom-lib/intention/engine";

const pseudo = `
# name: normalize2d
# target: js,py
# description:
Normalize a 2D vector (x,y). Return magnitude and normalized components.
# signature:
(x: number, y: number) -> { mag: number, nx: number, ny: number }
# constraints:
- Avoid division by zero; if both are 0, return zeros.
# examples:
^ref-c14edce7-353-0
- in: { "x":3, "y":4 } out: { "mag":5, "nx":0.6, "ny":0.8 }
- in: { "x":0, "y":0 } out: { "mag":0, "nx":0, "ny":0 }
^ref-c14edce7-384-0
^ref-c14edce7-383-0 ^ref-c14edce7-390-0
^ref-c14edce7-382-0
`; ^ref-c14edce7-392-0
^ref-c14edce7-397-0
^ref-c14edce7-395-0
^ref-c14edce7-394-0 ^ref-c14edce7-403-0
^ref-c14edce7-393-0
^ref-c14edce7-392-0 ^ref-c14edce7-405-0
^ref-c14edce7-390-0 ^ref-c14edce7-406-0
^ref-c14edce7-384-0 ^ref-c14edce7-407-0
^ref-c14edce7-383-0
^ref-c14edce7-382-0 ^ref-c14edce7-409-0
 ^ref-c14edce7-393-0
^ref-c14edce7-417-0 ^ref-c14edce7-418-0
^ref-c14edce7-416-0 ^ref-c14edce7-419-0
^ref-c14edce7-415-0 ^ref-c14edce7-420-0
^ref-c14edce7-409-0
^ref-c14edce7-407-0
^ref-c14edce7-406-0
^ref-c14edce7-405-0 ^ref-c14edce7-424-0
^ref-c14edce7-403-0
^ref-c14edce7-397-0 ^ref-c14edce7-426-0
^ref-c14edce7-395-0 ^ref-c14edce7-427-0
^ref-c14edce7-394-0 ^ref-c14edce7-428-0
^ref-c14edce7-393-0
^ref-c14edce7-392-0
^ref-c14edce7-390-0
^ref-c14edce7-384-0
^ref-c14edce7-383-0
^ref-c14edce7-382-0
^ref-c14edce7-381-0
const res = await transpileIntention(pseudo, { ^ref-c14edce7-382-0 ^ref-c14edce7-394-0
  // plug your real LLM here (OpenAI, local, etc.) ^ref-c14edce7-383-0 ^ref-c14edce7-395-0
  rounds: 3, ^ref-c14edce7-384-0
  outDir: { js: "src/js/auto", py: "src/py/auto" } ^ref-c14edce7-397-0
}); ^ref-c14edce7-415-0
console.log(res.out.map(o => ({ lang:o.lang, pass:o.pass }))); ^ref-c14edce7-416-0
``` ^ref-c14edce7-417-0
^ref-c14edce7-388-0
 ^ref-c14edce7-418-0
--- ^ref-c14edce7-390-0 ^ref-c14edce7-419-0
 ^ref-c14edce7-403-0 ^ref-c14edce7-420-0
# 4) Make it *really* “on the fly” ^ref-c14edce7-392-0
 ^ref-c14edce7-393-0 ^ref-c14edce7-405-0
* **Watch mode**: hook a file watcher to any `*.intent.md` → re-run `transpileIntention` on change; hot-reload the JS VM; keep Python process warm (bridge pool). ^ref-c14edce7-394-0 ^ref-c14edce7-406-0
* **Live REPL**: inside your Lisp, build a `(transpile! pseudo-string ...)` form that calls the engine (JS side), drops artifacts into your mirror, and returns a callable function (from VM or Python proxy). ^ref-c14edce7-395-0 ^ref-c14edce7-407-0 ^ref-c14edce7-424-0
* **Equivalence check across langs**: run both generated impls on randomized inputs (**fast-check** on JS / **hypothesis** on Py); if outputs disagree, send a repair prompt with a *diff summary*.
 ^ref-c14edce7-397-0 ^ref-c14edce7-409-0 ^ref-c14edce7-426-0
--- ^ref-c14edce7-427-0
 ^ref-c14edce7-428-0
# 5) Where the “magic” lives (LLM prompting)

You’ll want a slightly smarter prompt set:
 ^ref-c14edce7-403-0 ^ref-c14edce7-415-0
* **System**: strict role; language; “single file, pass examples, no commentary”. ^ref-c14edce7-416-0
* **Few-shot**: include 2–3 solved micro-tasks with signature+examples→final code for that language. ^ref-c14edce7-405-0 ^ref-c14edce7-417-0
* **Formatting**: tell it to emit *only* the module code. ^ref-c14edce7-406-0 ^ref-c14edce7-418-0
* **Repair**: show test failures and current code; ask for a *patch* or full file (I recommend full file v1). ^ref-c14edce7-407-0 ^ref-c14edce7-419-0
 ^ref-c14edce7-420-0
You can pop those into `planner.ts` as templated strings. ^ref-c14edce7-409-0

---
 ^ref-c14edce7-424-0
# 6) JS↔Python interop from the same intention
 ^ref-c14edce7-426-0
If the planner infers heavy numerics (“use numpy”), set `targets: ["py"]` and **expose a JS wrapper** automatically: ^ref-c14edce7-415-0 ^ref-c14edce7-427-0
 ^ref-c14edce7-416-0 ^ref-c14edce7-428-0
* Generate Python “core” + a tiny JS veneer that calls it via the **bridge** so your JS apps import `normalize2d` and “don’t notice” it’s Python. ^ref-c14edce7-417-0
* For Node: bundle the fast bridge function into the wrapper. ^ref-c14edce7-418-0
* For the browser: swap in the Pyodide transport. ^ref-c14edce7-419-0
 ^ref-c14edce7-420-0
*(If you want, I’ll add `emitWrapperJS(spec)` that writes `src/js/auto/normalize2d.wrapper.js` calling the Python function.)*

---
 ^ref-c14edce7-424-0
# 7) Next upgrades (pick what you want next)
 ^ref-c14edce7-426-0
* **Real LLM provider**: plugin for your model (OpenAI, local llama.cpp, vLLM). I can hand you a drop-in `OpenAIProvider`. ^ref-c14edce7-427-0
* **Structured outputs**: instruct the LLM to return JSON with `{filename, code, tests}`; parse with a ReACT validator. ^ref-c14edce7-428-0
* **Static checks**: run `tsc --noEmit`, `eslint`, `ruff`, `mypy` as extra gates before we “pass”.
* **Property tests**: autogenerate from signature + constraints (e.g., `mag ≥ 0`, “no NaN”), and shrink on failure.
* **IR anchor**: lower generated code to your ANF IR, compute `irHash`, and store in `.promirror/` so the rector can keep multi-language artifacts in sync with a *single* intention source.
* **Editor hooks**: VS Code/Neovim command that runs the engine on the current block, inserts code or test diffs live.

---

If you want, I’ll:

1. plug in a real OpenAI provider (with minimal dependencies),
2. add the **JS wrapper → Python** path so you can call numpy-powered functions from JS with zero ceremony, or
3. bolt on watch mode + a tiny REPL so you can type pseudo and immediately call the function.
