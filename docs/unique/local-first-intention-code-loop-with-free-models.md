---
uuid: 006182ac-45a4-449d-8a60-c9bd5a3a9bff
created_at: local-first-intention-code-loop-with-free-models.md
filename: local-first-intention-code-loop
title: local-first-intention-code-loop
description: >-
  A local-first approach to running the intention→code loop using free/local
  models for fast, reliable, and swappable execution without paid APIs.
tags:
  - local-first
  - intention-code-loop
  - free-models
related_to_uuid:
  - 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
  - e9b27b06-f608-4734-ae6c-f03a8b1fcf5f
  - fc21f824-4244-4030-a48e-c4170160ea1d
  - a4a25141-6380-40b9-9cd7-b554b246b303
  - 1cfae310-35dc-49c2-98f1-b186da25d84b
  - 6620e2f2-de6d-45d8-a722-5d26e160b370
  - dd00677a-2280-45a7-91af-0728b21af3ad
  - 5e408692-0e74-400e-a617-84247c7353ad
  - 291c7d91-da8c-486c-9bc0-bd2254536e2d
  - dd89372d-10de-42a9-8c96-6bc13ea36d02
  - 64a9f9f9-58ee-4996-bdaf-9373845c6b29
  - 2792d448-c3b5-4050-93dd-93768529d99c
  - 1f32c94a-4da4-4266-8ac0-6c282cfb401f
  - 22b989d5-f4aa-4880-8632-709c21830f83
  - bb7f0835-c347-474f-bfad-eabd873b51ad
  - 930054b3-ba95-4acf-bb92-0e3ead25ed0b
  - 5020e892-8f18-443a-b707-6d0f3efcfe22
  - 78eeedf7-75bc-4692-a5a7-bb6857270621
  - ed6f3fc9-5eb1-482c-8b3c-f0abc5aff2a2
  - 30ec3ba6-fbca-4606-ac3e-89b747fbeb7c
  - 62bec6f0-4e13-4f38-aca4-72c84ba02367
  - 1b1338fc-bb4d-41df-828f-e219cc9442eb
  - 10d98225-12e0-4212-8e15-88b57cf7bee5
  - 13951643-1741-46bb-89dc-1beebb122633
  - 008f2ac0-bfaa-4d52-9826-2d5e86c0059f
related_to_title:
  - aionian-circuit-math
  - field-node-diagram-visualizations
  - Fnord Tracer Protocol
  - Functional Embedding Pipeline Refactor
  - Functional Refactor of TypeScript Document Processing
  - graph-ds
  - heartbeat-fragment-demo
  - i3-bluetooth-setup
  - Ice Box Reorganization
  - komorebi-group-window-hack
  - Layer1SurvivabilityEnvelope
  - Docops Feature Updates
  - field-node-diagram-outline
  - field-node-diagram-set
  - Agent Reflections and Prompt Evolution
  - ChatGPT Custom Prompts
  - Chroma Toolkit Consolidation Plan
  - typed-struct-compiler
  - Unique Concepts
  - Unique Info Dump Index
  - zero-copy-snapshots-and-workers
  - Canonical Org-Babel Matplotlib Animation Template
  - Creative Moments
  - Duck's Attractor States
  - eidolon-field-math-foundations
references:
  - uuid: e9b27b06-f608-4734-ae6c-f03a8b1fcf5f
    line: 4516
    col: 0
    score: 1
  - uuid: fc21f824-4244-4030-a48e-c4170160ea1d
    line: 6833
    col: 0
    score: 1
  - uuid: a4a25141-6380-40b9-9cd7-b554b246b303
    line: 3596
    col: 0
    score: 1
  - uuid: 1cfae310-35dc-49c2-98f1-b186da25d84b
    line: 2846
    col: 0
    score: 1
  - uuid: 6620e2f2-de6d-45d8-a722-5d26e160b370
    line: 5671
    col: 0
    score: 1
  - uuid: dd00677a-2280-45a7-91af-0728b21af3ad
    line: 4921
    col: 0
    score: 1
  - uuid: 5e408692-0e74-400e-a617-84247c7353ad
    line: 5384
    col: 0
    score: 1
  - uuid: 291c7d91-da8c-486c-9bc0-bd2254536e2d
    line: 4881
    col: 0
    score: 1
  - uuid: dd89372d-10de-42a9-8c96-6bc13ea36d02
    line: 4647
    col: 0
    score: 1
  - uuid: 64a9f9f9-58ee-4996-bdaf-9373845c6b29
    line: 5410
    col: 0
    score: 1
  - uuid: bb7f0835-c347-474f-bfad-eabd873b51ad
    line: 618
    col: 0
    score: 1
  - uuid: 930054b3-ba95-4acf-bb92-0e3ead25ed0b
    line: 187
    col: 0
    score: 1
  - uuid: 5020e892-8f18-443a-b707-6d0f3efcfe22
    line: 999
    col: 0
    score: 1
  - uuid: 78eeedf7-75bc-4692-a5a7-bb6857270621
    line: 1016
    col: 0
    score: 1
  - uuid: ed6f3fc9-5eb1-482c-8b3c-f0abc5aff2a2
    line: 175
    col: 0
    score: 1
  - uuid: 30ec3ba6-fbca-4606-ac3e-89b747fbeb7c
    line: 1221
    col: 0
    score: 1
  - uuid: 62bec6f0-4e13-4f38-aca4-72c84ba02367
    line: 1058
    col: 0
    score: 1
  - uuid: 1b1338fc-bb4d-41df-828f-e219cc9442eb
    line: 515
    col: 0
    score: 1
  - uuid: 10d98225-12e0-4212-8e15-88b57cf7bee5
    line: 251
    col: 0
    score: 1
  - uuid: 13951643-1741-46bb-89dc-1beebb122633
    line: 559
    col: 0
    score: 1
  - uuid: 008f2ac0-bfaa-4d52-9826-2d5e86c0059f
    line: 1033
    col: 0
    score: 1
  - uuid: 2792d448-c3b5-4050-93dd-93768529d99c
    line: 226
    col: 0
    score: 1
  - uuid: 1f32c94a-4da4-4266-8ac0-6c282cfb401f
    line: 705
    col: 0
    score: 1
  - uuid: 22b989d5-f4aa-4880-8632-709c21830f83
    line: 719
    col: 0
    score: 1
  - uuid: e9b27b06-f608-4734-ae6c-f03a8b1fcf5f
    line: 601
    col: 0
    score: 1
  - uuid: fc21f824-4244-4030-a48e-c4170160ea1d
    line: 1060
    col: 0
    score: 1
  - uuid: a4a25141-6380-40b9-9cd7-b554b246b303
    line: 726
    col: 0
    score: 1
  - uuid: 6620e2f2-de6d-45d8-a722-5d26e160b370
    line: 996
    col: 0
    score: 1
  - uuid: dd00677a-2280-45a7-91af-0728b21af3ad
    line: 667
    col: 0
    score: 1
  - uuid: 5e408692-0e74-400e-a617-84247c7353ad
    line: 736
    col: 0
    score: 1
  - uuid: 291c7d91-da8c-486c-9bc0-bd2254536e2d
    line: 645
    col: 0
    score: 1
  - uuid: dd89372d-10de-42a9-8c96-6bc13ea36d02
    line: 739
    col: 0
    score: 1
  - uuid: 64a9f9f9-58ee-4996-bdaf-9373845c6b29
    line: 816
    col: 0
    score: 1
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 1
    col: 0
    score: 1
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 3
    col: 0
    score: 1
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 9
    col: 0
    score: 1
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 11
    col: 0
    score: 1
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 13
    col: 0
    score: 1
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 17
    col: 0
    score: 1
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 19
    col: 0
    score: 1
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 66
    col: 0
    score: 0.97
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 85
    col: 0
    score: 0.97
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 105
    col: 0
    score: 0.96
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 40
    col: 0
    score: 0.96
  - uuid: 6420e101-2d34-45b5-bcff-d21e1c6e516b
    line: 17
    col: 0
    score: 0.93
  - uuid: ed2e157e-bfed-4291-ae4c-6479df975d87
    line: 113
    col: 0
    score: 0.92
  - uuid: ed2e157e-bfed-4291-ae4c-6479df975d87
    line: 17
    col: 0
    score: 0.91
  - uuid: 4f9a7fd9-de08-4b9c-87c4-21268bc26d54
    line: 19
    col: 0
    score: 0.91
  - uuid: 03a5578f-d689-45db-95e9-11300e5eee6f
    line: 4993
    col: 0
    score: 0.9
  - uuid: 9413237f-2537-4bbf-8768-db6180970e36
    line: 125
    col: 0
    score: 0.9
  - uuid: 3a3bf2c9-c0f6-4d7b-bf84-c83c70dece3f
    line: 311
    col: 0
    score: 0.9
  - uuid: c0392040-16a2-41e8-bd54-75110319e3c0
    line: 120
    col: 0
    score: 0.9
  - uuid: 0b872af2-4197-46f3-b631-afb4e6135585
    line: 2159
    col: 0
    score: 0.9
  - uuid: 2d6e5553-8dc4-497f-bf45-96f8ca00a6f6
    line: 3621
    col: 0
    score: 0.9
  - uuid: 95205cd3-c3d5-4047-9c33-9c5ca2b49597
    line: 148
    col: 0
    score: 0.9
  - uuid: 23df6ddb-05cf-4639-8201-f8291f8a6026
    line: 4048
    col: 0
    score: 0.9
  - uuid: d614d983-7795-491f-9437-09f3a43f72cf
    line: 2381
    col: 0
    score: 0.9
  - uuid: 4f9a7fd9-de08-4b9c-87c4-21268bc26d54
    line: 17
    col: 0
    score: 0.9
  - uuid: ed2e157e-bfed-4291-ae4c-6479df975d87
    line: 82
    col: 0
    score: 0.9
  - uuid: 6420e101-2d34-45b5-bcff-d21e1c6e516b
    line: 77
    col: 0
    score: 0.9
  - uuid: ba244286-4e84-425b-8bf6-b80c4eb783fc
    line: 374
    col: 0
    score: 0.89
  - uuid: 2c00ce45-08cf-4b81-9883-6157f30b7fae
    line: 279
    col: 0
    score: 0.89
  - uuid: 6498b9d7-bd35-4bd3-89fb-af1c415c3cd1
    line: 427
    col: 0
    score: 0.89
  - uuid: 4f9a7fd9-de08-4b9c-87c4-21268bc26d54
    line: 9
    col: 0
    score: 0.89
  - uuid: ed2e157e-bfed-4291-ae4c-6479df975d87
    line: 37
    col: 0
    score: 0.89
  - uuid: aee4718b-9f8b-4635-a0c1-ef61c9bea8f1
    line: 306
    col: 0
    score: 0.88
  - uuid: 31f0166e-4631-45fa-aecd-b44e9a13f497
    line: 79
    col: 0
    score: 0.88
  - uuid: c5fba0a0-9196-468d-a0f3-51c99e987263
    line: 148
    col: 0
    score: 0.88
  - uuid: 7a75d992-5267-4557-b464-b6c7d3f88dad
    line: 59
    col: 0
    score: 0.88
  - uuid: ed2e157e-bfed-4291-ae4c-6479df975d87
    line: 62
    col: 0
    score: 0.88
  - uuid: 8792b6d3-aafd-403f-a410-e8a09ec2f8cf
    line: 128
    col: 0
    score: 0.88
  - uuid: 4f9a7fd9-de08-4b9c-87c4-21268bc26d54
    line: 81
    col: 0
    score: 0.88
  - uuid: ed2e157e-bfed-4291-ae4c-6479df975d87
    line: 102
    col: 0
    score: 0.88
  - uuid: e811123d-5841-4e52-bf8c-978f26db4230
    line: 630
    col: 0
    score: 0.87
  - uuid: d527c05d-22e8-4493-8f29-ae3cb67f035b
    line: 400
    col: 0
    score: 0.87
  - uuid: 10d98225-12e0-4212-8e15-88b57cf7bee5
    line: 626
    col: 0
    score: 0.87
  - uuid: 2aafc801-c3e1-4e4f-999d-adb52af3fc41
    line: 92
    col: 0
    score: 0.86
  - uuid: b4e64f8c-4dc9-4941-a877-646c5ada068e
    line: 348
    col: 0
    score: 0.86
  - uuid: cf6b9b17-bb91-4219-aa5c-172cba02b2da
    line: 111
    col: 0
    score: 0.86
  - uuid: 36c8882a-badc-4e18-838d-2c54d7038141
    line: 161
    col: 0
    score: 0.86
  - uuid: ab54cdd8-13ce-4dcb-a9cd-da2d86e0305f
    line: 272
    col: 0
    score: 0.86
  - uuid: d2b3628c-6cad-4664-8551-94ef8280851d
    line: 504
    col: 0
    score: 0.85
  - uuid: af5d2824-faad-476c-a389-e912d9bc672c
    line: 120
    col: 0
    score: 0.85
  - uuid: b362e12e-2802-4e41-9a21-6e0c7ad419a2
    line: 151
    col: 0
    score: 0.85
  - uuid: c5c5ff1c-d1bc-45c7-8a84-55a4a847dfc5
    line: 185
    col: 0
    score: 0.85
  - uuid: 36c8882a-badc-4e18-838d-2c54d7038141
    line: 137
    col: 0
    score: 0.85
  - uuid: 534fe91d-e87d-4cc7-b0e7-8b6833353d9b
    line: 527
    col: 0
    score: 0.85
---
Totally get it. Local-first is the whole vibe. Let’s make your **intention→code** loop run on *your* box with free/local models — and be fast, reliable, and swappable. ^ref-871490c7-1-0

Here’s a tight, drop-in stack: ^ref-871490c7-3-0

# 1) Local LLMs: router + cache (no paid APIs)

```ts
// shared/js/prom-lib/intention/router.ts
import type { LLM } from "./llm";

export class RouterLLM implements LLM {
  constructor(private providers: LLM[]) {}
  async generate(io: { system: string; prompt: string }): Promise<string> {
    let lastErr: any;
    for (const p of this.providers) {
      try { return await p.generate(io); } catch (e) { lastErr = e; }
    }
    throw lastErr ?? new Error("No providers responded");
  }
}
```
^ref-871490c7-7-0 ^ref-871490c7-22-0
 ^ref-871490c7-23-0
```ts
// shared/js/prom-lib/intention/cache.ts
import { createHash } from "node:crypto";
import { promises as fs } from "node:fs";
import * as path from "node:path";
import type { LLM } from "./llm";

export class FileCacheLLM implements LLM {
  constructor(private inner: LLM, private dir = ".promirror/cache") {}
  private key(s: string) { return createHash("sha256").update(s).digest("hex"); }
  async generate({ system, prompt }: { system: string; prompt: string }) {
    await fs.mkdir(this.dir, { recursive: true });
    const k = this.key(system + "\n---\n" + prompt);
    const p = path.join(this.dir, k + ".txt");
    try { return await fs.readFile(p, "utf8"); } catch {}
    const out = await this.inner.generate({ system, prompt });
    await fs.writeFile(p, out, "utf8");
    return out;
  }
}
^ref-871490c7-23-0
```

# 2) Providers: Ollama (you already have) + OpenAI-compatible (LM Studio, vLLM, TGI) ^ref-871490c7-47-0

````ts
// shared/js/prom-lib/intention/openai_compat.ts
import type { LLM } from "./llm";

export class OpenAICompatLLM implements LLM {
  constructor(
    private baseUrl = "     // LM Studio default
    private model = "qwen2.5-coder:7b",
    private apiKey = "sk-local",                      // ignored by most local servers
    private params: Partial<{ temperature: number; top_p: number; max_tokens: number; stop: string[] }> = {},
  ) {}
  async generate({ system, prompt }: { system: string; prompt: string }) {
    const r = await fetch(`${this.baseUrl}/chat/completions`, {
      method: "POST",
      headers: { "Content-Type": "application/json", "Authorization": `Bearer ${this.apiKey}` },
      body: JSON.stringify({
        model: this.model,
        messages: [
          { role: "system", content: `${system}\nReturn ONLY code. No fences.` },
          { role: "user", content: prompt },
        ],
        temperature: 0.1, top_p: 0.95, max_tokens: 1024, stop: ["```", ...(this.params.stop ?? [])],
        ...this.params,
        stream: false
      })
    });
    if (!r.ok) throw new Error(`openai-compat ${r.status}: ${await r.text().catch(()=>"<no body>")}`);
    const j: any = await r.json();
    const text = j.choices?.[0]?.message?.content ?? "";
    return text.replace(/^```[\w-]*\n?|\n?```$/g, "");
  }
^ref-871490c7-47-0
} ^ref-871490c7-81-0
````
 ^ref-871490c7-83-0
And your existing `OllamaLLM` (from that last message). Now compose:

```ts
// boot it
import { RouterLLM } from "./router";
import { FileCacheLLM } from "./cache";
import { OllamaLLM } from "./ollama";
import { OpenAICompatLLM } from "./openai_compat";

const local = new RouterLLM([
  new OllamaLLM({ model: "qwen2.5-coder:14b", options:{ temperature:0.1, num_predict: 1024 } }),
  new OpenAICompatLLM(" "deepseek-coder:6.7b") // LM Studio fallback
]);
^ref-871490c7-83-0

export const LocalLLM = new FileCacheLLM(local, ".promirror/cache");
```
^ref-871490c7-100-0 ^ref-871490c7-101-0

# 3) Plug into the transpiler

```ts
// wherever you call transpileIntention(...)
import { transpileIntention } from "./shared/js/prom-lib/intention/engine";
import { LocalLLM } from "./shared/js/prom-lib/intention/boot-local";

await transpileIntention(pseudoSpec, {
  llm: LocalLLM,
^ref-871490c7-100-0
  rounds: 3,
  outDir: { js: "src/js/auto", py: "src/py/auto" }
}); ^ref-871490c7-114-0
^ref-871490c7-114-0 ^ref-871490c7-116-0
``` ^ref-871490c7-117-0
^ref-871490c7-105-0
^ref-871490c7-114-0 ^ref-871490c7-118-0
^ref-871490c7-105-0 ^ref-871490c7-119-0
^ref-871490c7-114-0 ^ref-871490c7-118-0 ^ref-871490c7-120-0
 ^ref-871490c7-116-0 ^ref-871490c7-118-0 ^ref-871490c7-119-0 ^ref-871490c7-121-0
# 4) Local-first tips (to keep it snappy) ^ref-871490c7-117-0 ^ref-871490c7-119-0 ^ref-871490c7-120-0
 ^ref-871490c7-118-0 ^ref-871490c7-120-0 ^ref-871490c7-121-0
* **Pick models that fly on CPU/GPU:** ^ref-871490c7-119-0 ^ref-871490c7-121-0
 ^ref-871490c7-120-0 ^ref-871490c7-125-0
  * *JS code:* `qwen2.5-coder:7b` or `deepseek-coder:6.7b`. ^ref-871490c7-121-0
  * *General:* `llama3.1:8b-instruct` (solid reasoning for repair passes). ^ref-871490c7-125-0 ^ref-871490c7-127-0
* **Quantization:** prefer Q5\_K\_M / Q6\_K for speed-quality balance in Ollama. ^ref-871490c7-125-0
* **Prompt schedule:** round 1 small fast model, repair on bigger one (Router handles order). ^ref-871490c7-127-0
* **Determinism:** set `temperature: 0.1` (or 0), fixed `seed` if your server supports it. ^ref-871490c7-125-0 ^ref-871490c7-127-0
* **Cache everything:** that file cache saves tons of cycles when you re-run tests.

# 5) Optional: grammar lock (emit only code)

If your server supports **JSON schema** or **grammar**, great. Otherwise, this little post-filter mows down junk:

````ts
export function extractCode(s: string) {
^ref-871490c7-127-0
  const fence = s.match(/```[a-zA-Z-]*\n([\s\S]*?)```/); if (fence) return fence[1]; ^ref-871490c7-135-0
  const triple = s.split(/\n-{3,}\n/)[0]; // drop after separators
  return triple.trim();
^ref-871490c7-139-0
^ref-871490c7-135-0 ^ref-871490c7-141-0
} ^ref-871490c7-142-0
^ref-871490c7-143-0 ^ref-871490c7-144-0
^ref-871490c7-142-0
^ref-871490c7-141-0 ^ref-871490c7-146-0
^ref-871490c7-139-0 ^ref-871490c7-147-0
^ref-871490c7-147-0 ^ref-871490c7-150-0
^ref-871490c7-146-0
^ref-871490c7-144-0
^ref-871490c7-143-0
^ref-871490c7-142-0 ^ref-871490c7-154-0
^ref-871490c7-141-0 ^ref-871490c7-155-0
^ref-871490c7-139-0 ^ref-871490c7-156-0
^ref-871490c7-135-0
```` ^ref-871490c7-139-0 ^ref-871490c7-143-0
 ^ref-871490c7-144-0 ^ref-871490c7-150-0
Use it inside providers before returning. ^ref-871490c7-141-0 ^ref-871490c7-160-0
 ^ref-871490c7-142-0 ^ref-871490c7-146-0
--- ^ref-871490c7-143-0 ^ref-871490c7-147-0
 ^ref-871490c7-144-0 ^ref-871490c7-154-0
Want me to also wire a **watcher CLI** (auto-transpile on `*.intent.md` change) and a **dual-model round schedule** baked into the engine? Or set up a **tiny config file** so you can switch models/endpoints without touching code?
