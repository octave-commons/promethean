There are two pathways for setting up a codex environment:
- full setup
- lighter maintenance script.

Both should populate an
artifacts folder that is ignored by Git but accessible to the agent as soon as
it starts.

The maintenance script only has to run project level stuff, like install, build, lint, etc.
I have tried to separate tasks which are ran in both into their own scripts.

Rewrite the setup, maintenance, and utility scripts below using the new `describe` helper.

I want each run of the scripts to generate unique files with dates in their titles,
and for there to be a single entry file with links to each of the generated files,
and some statistics (build fail/succeed, test fail/pass, eslint warn/err, etc)



## `run/codex_maintenance.sh`

```bash
#!/usr/bin/env bash

echo "# Codex Cloud Maintenance Report Start:$(date +"%Y.%m.%d.%H.%M.%S")"
pnpm install --no-frozen-lockfile

bash ./run/setup_gh_cli.sh >"$ART_DIR/setup_gh_cli.txt" 2>&1

# start the server if not running
curl -fsS http://127.0.0.1:8000/api/v2/heartbeat >/dev/null 2>&1 || \
    nohup uvx --from chromadb chroma run --host 127.0.0.1 --port 8000 >/dev/null 2>&1 &


# wait for health (60s timeout each)
if ! timeout 60s bash -c 'until curl -fsS http://127.0.0.1:8000/api/v2/heartbeat >/dev/null; do sleep 1; done'; then
    echo "ChromaDB failed to become healthy in 60s" >&2
    exit 1
fi


# Start ollama if it isn't already running
bash ./run/standup_ollama_nohup.sh


bash ./run/standup_chroma_nohup.sh


# Prime caches & collect Nx artifacts without failing the job
NX_BASE="${NX_BASE:-origin/main}" \
       NX_HEAD="${NX_HEAD:-HEAD}" \
       NX_STRICT="${NX_STRICT:-0}" \
       ART_ROOT="docs/reports/codex_cloud" \
       bash ./run/nx_artifacts.sh || true

echo "# Codex Cloud Maintenance Report End:$(date +"%Y.%m.%d.%H.%M.%S")"
```
## `run/setup_codex_dev_env.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail

echo "# Codex Cloud Setup Report Start:$(date +"%Y.%m.%d.%H.%M.%S")"

ART_DIR="docs/reports/codex_cloud"
mkdir -p "$ART_DIR"

# capture env for debugging instead of spamming stdout
(set -o posix; set) > "$ART_DIR/env.txt" 2>&1 || true

command -v uvx >/dev/null || { echo "uvx not found on PATH after install" >&2; exit 1; }

uvx pre-commit install
uvx pre-commit install --install-hooks
uvx pre-commit install --hook-type commit-msg
uvx pre-commit install --hook-type pre-merge-commit

# base toolchain (noninteractive so CI won’t hang)
export DEBIAN_FRONTEND=noninteractive
apt-get update -y >"$ART_DIR/apt_update.txt" 2>&1
apt-get install -y build-essential python3 make g++ pkg-config >"$ART_DIR/apt_build_tools.txt" 2>&1
apt-get install -y git ca-certificates jq moreutils ripgrep >"$ART_DIR/apt_extras.txt" 2>&1

bash ./run/install_gyp.sh >"$ART_DIR/install_gyp.txt" 2>&1

corepack enable >"$ART_DIR/corepack_enable.txt" 2>&1
corepack prepare pnpm@9.0.0 --activate >"$ART_DIR/corepack_prepare.txt" 2>&1
pnpm install --frozen-lockfile >"$ART_DIR/pnpm_install.txt" 2>&1

bash ./run/setup_playwright.sh >"$ART_DIR/setup_playwright.txt" 2>&1 || true

bash ./run/install_gh_cli.sh >"$ART_DIR/install_gh_cli.txt" 2>&1
bash ./run/setup_gh_cli.sh >"$ART_DIR/setup_gh_cli.txt" 2>&1

bash ./run/standup_chroma_nohup.sh

# install
curl -fsSL https://ollama.com/install.sh | sh >"$ART_DIR/ollama_install.txt" 2>&1
# Start ollama if it isn't already running
bash ./run/standup_ollama_nohup.sh

npm install --global corepack@latest >"$ART_DIR/npm_corepack.txt" 2>&1 || true
npm install -g eslint >"$ART_DIR/npm_eslint.txt" 2>&1 || true

# --------------------------
# Check phase: never bail early; capture artifacts
# --------------------------
SOFT_FAIL="${SOFT_FAIL:-1}"  # 1 = always exit 0 (soft), 0 = fail at end (hard)
BUILD_LOG="$ART_DIR/initial_build.txt"
LINT_LOG="$ART_DIR/initial_eslint.txt"
LINT_JSON="$ART_DIR/initial_eslint.json"
SUMMARY_JSON="$ART_DIR/summary.json"

# Decide how to run: Nx affected speeds things up if present
NX_RUNNER="pnpm -s -r --no-bail build"
if pnpm exec nx --version >/dev/null 2>&1; then
  # Prime Nx graph & cache info; prefer affected if git is available
  if git rev-parse --is-inside-work-tree >/dev/null 2>&1; then
    NX_RUNNER="pnpm exec nx affected -t build --parallel --output-style=stream"
  else
    NX_RUNNER="pnpm exec nx run-many -t build --parallel --output-style=stream"
  fi
fi

# run build + lint without -e so we can collect exit codes
set +e
/usr/bin/time -p bash -c "$NX_RUNNER" >"$BUILD_LOG" 2>&1
build_rc=$?

# produce both human and machine-readable lint artifacts
/usr/bin/time -p pnpm exec eslint --cache -f stylish . >"$LINT_LOG" 2>&1
eslint_rc=$?

# JSON report (for agents to parse quickly)
pnpm exec eslint --cache -f json . >"$LINT_JSON" 2>&1
eslint_json_rc=$?
set -e

# Summarize for the agent
jq -n \
  --arg now "$(date -Is)" \
  --arg nx_runner "$NX_RUNNER" \
  --arg build_log "$BUILD_LOG" \
  --arg lint_log "$LINT_LOG" \
  --arg lint_json "$LINT_JSON" \
  --arg pnpm_version "$(pnpm --version 2>/dev/null || echo unknown)" \
  --arg eslint_version "$(pnpm exec eslint --version 2>/dev/null || echo unknown)" \
  --arg node_version "$(node --version 2>/dev/null || echo unknown)" \
  --argjson build_rc "$build_rc" \
  --argjson eslint_rc "$eslint_rc" \
  --argjson eslint_json_rc "$eslint_json_rc" \
  '{
     timestamp: $now,
     runner: $nx_runner,
     env: { pnpm: $pnpm_version, eslint: $eslint_version, node: $node_version },
     artifacts: { build_log: $build_log, lint_log: $lint_log, lint_json: $lint_json },
     status: { build: $build_rc, eslint_stylish: $eslint_rc, eslint_json: $eslint_json_rc },
     advice: [
       "Open \( $build_log ) for build errors.",
       "Open \( $lint_log ) for human readable lint output.",
       "Open \( $lint_json ) to programmatically inspect lint issues."
     ]
   }' >"$SUMMARY_JSON"

# Friendly pointers on stdout for the agent
echo "Artifacts ready:"
echo "  Build log:     $BUILD_LOG"
echo "  ESLint log:    $LINT_LOG"
echo "  ESLint JSON:   $LINT_JSON"
echo "  Summary JSON:  $SUMMARY_JSON"
# Prime caches & collect Nx artifacts without failing the job
NX_BASE="${NX_BASE:-origin/main}" \
       NX_HEAD="${NX_HEAD:-HEAD}" \
       NX_STRICT="${NX_STRICT:-0}" \
       ART_ROOT="docs/reports/codex_cloud" \
       bash ./run/nx_artifacts.sh || true

echo "# Codex Cloud Setup Report End:$(date +"%Y.%m.%d.%H.%M.%S")"
# If you ever want the whole script to fail at the end based on Nx:
# NX_STRICT=1 bash ./run/nx_artifacts.sh

# Exit policy
if [ "$SOFT_FAIL" -eq 1 ]; then
  exit 0
fi

# Hard fail at the very end if either check failed
if [ "$build_rc" -ne 0 ] || [ "$eslint_rc" -ne 0 ] || [ "$eslint_json_rc" -ne 0 ]; then
  exit 1
fi

exit 0
```

## `run/standup_nohup_ollama.sh`

```bash
#!/usr/bin/env bash
pgrep -f 'ollama serve' >/dev/null || nohup ollama serve >"$ART_DIR/ollama_nohup.txt" 2>&1 &

if ! timeout 60s bash -c 'until curl -fsS http://127.0.0.1:11434/api/tags >/dev/null; do sleep 1; done'; then
  echo "Ollama daemon failed to become ready in 60s" | tee -a "$ART_DIR/ollama_health.txt" >&2
  exit 1
fi

ollama pull qwen2.5:0.5b >"$ART_DIR/ollama_pull_qwen.txt" 2>&1 || true
ollama pull nomic-embed-text >"$ART_DIR/ollama_pull_embed.txt" 2>&1 || true
```


## `run/install_gyp.sh`

```bash
#!/usr/bin/env bash
# setup-native-node-build.sh
# Ubuntu/Debian: install system deps for native Node builds, pin global node-gyp, and harden PATH.

set -euo pipefail

#--- Helpers ---------------------------------------------------------------
log() { printf "\033[1;32m[setup]\033[0m %s\n" "$*"; }
warn() { printf "\033[1;33m[warn]\033[0m %s\n" "$*"; }
die() { printf "\033[1;31m[err]\033[0m %s\n" "$*"; exit 1; }

#--- OS guard --------------------------------------------------------------
if ! command -v apt-get >/dev/null 2>&1; then
  die "This script targets Debian/Ubuntu (apt-get not found)."
fi

#--- 1) Toolchain for node-gyp (Python, make, C/C++ compiler, pkg-config) ---
# node-gyp needs Python + make + a proper C/C++ toolchain. :contentReference[oaicite:4]{index=4}
log "Installing core build toolchain (Python, make, g++, pkg-config)…"
sudo apt-get update -y
sudo apt-get install -y python3 make g++ pkg-config build-essential

#--- 2) Canvas system libraries (Cairo/Pango/JPEG/GIF/SVG) -----------------
# Canonical deps from node-canvas docs. :contentReference[oaicite:5]{index=5}
log "Installing node-canvas dependencies (Cairo/Pango/jpeg/gif/svg)…"
sudo apt-get install -y libcairo2-dev libpango1.0-dev libjpeg-dev libgif-dev librsvg2-dev

#--- 3) Voice stack libs for @discordjs/opus --------------------------------
# Native bindings to libopus; ffmpeg commonly used alongside. :contentReference[oaicite:6]{index=6}
log "Installing Opus/FFmpeg for @discordjs/opus…"
sudo apt-get install -y libopus-dev ffmpeg

#--- 4) Ensure Corepack & pnpm (optional but handy in fresh envs) ----------
if ! command -v pnpm >/dev/null 2>&1; then
  log "Enabling Corepack and preparing pnpm (optional)…"
  if command -v corepack >/dev/null 2>&1; then
    corepack enable || true
    corepack prepare pnpm@latest --activate || true
  else
    warn "corepack not found; skipping pnpm bootstrap."
  fi
fi

#--- 5) Install node-gyp globally & pin npm to it --------------------------
# npm uses the `node_gyp` config to locate the binary for lifecycle builds. :contentReference[oaicite:7]{index=7}
log "Installing node-gyp globally…"
npm i -g node-gyp@latest

# Find global npm prefix & binary path
NPM_PREFIX=$(npm prefix -g)
NODE_GYP_BIN="$NPM_PREFIX/lib/node_modules/node-gyp/bin/node-gyp.js"
#--- 6) Ensure npm global bin is on PATH for interactive shells ------------
# npm honors env vars like NPM_CONFIG_* for config; PATH still matters for tools you run. :contentReference[oaicite:8]{index=8}
NPM_BIN_DIR="$NPM_PREFIX/bin"

#--- 7) Show effective config ------------------------------------------------
log "Verifying configuration…"
echo "npm config get node_gyp  => $(npm config get node_gyp)"
echo "node-gyp --version       => $(node-gyp --version || echo 'NOT FOUND IN PATH')"
echo "Global npm bin dir       => $NPM_BIN_DIR"

log "Done. You can now run: pnpm install --reporter=ndjson --loglevel silly"

```

## `run/install_gh_cli.sh`

```bash
#!/usr/bin/env bash
(type -p wget >/dev/null || (sudo apt update && sudo apt install wget -y)) \
	  && sudo mkdir -p -m 755 /etc/apt/keyrings \
	  && out=$(mktemp) && wget -nv -O$out https://cli.github.com/packages/githubcli-archive-keyring.gpg \
	  && cat $out | sudo tee /etc/apt/keyrings/githubcli-archive-keyring.gpg > /dev/null \
	  && sudo chmod go+r /etc/apt/keyrings/githubcli-archive-keyring.gpg \
	  && sudo mkdir -p -m 755 /etc/apt/sources.list.d \
	  && echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null \
	  && sudo apt update \
	  && sudo apt install gh -y
```


## `run/setup_gh_cli.sh`


```bash
#!/usr/bin/env bash
set -euo pipefail

# ----------- required runtime env -----------
: "${GH_TOKEN:?GH_TOKEN must be set}"
: "${REPO_SLUG:?REPO_SLUG must be set, e.g. owner/repo}"

# Optional: master switch for protocol: https|ssh
PROTO="${PROTO:-https}"

# Optional: branch to check out if repo is missing
BRANCH="${BRANCH:-main}"

# ----------- utilities -----------
need() { command -v "$1" >/dev/null 2>&1; }

# Install basics if missing (Debian/Ubuntu; adjust for your base)
if ! need git; then
  apt-get update -y && apt-get install -y git
fi
if ! need gh; then
  apt-get update -y && apt-get install -y gh
fi
if [ "$PROTO" = "ssh" ] && ! need ssh; then
  apt-get update -y && apt-get install -y openssh-client
fi

# Disable gh prompts; avoid accidental TTY blocking
gh config set prompt disabled true

# Login non-interactively (stdin avoids token showing up in ps/history)
printf '%s' "$GH_TOKEN" | gh auth login --with-token >/dev/null

# Let gh wire Git credentials for HTTPS
gh auth setup-git >/dev/null 2>&1 || true

# ----------- compute URLs -----------
if [ "$PROTO" = "ssh" ]; then
  CLONE_URL="git@github.com:${REPO_SLUG}.git"
else
  CLONE_URL="https://github.com/${REPO_SLUG}.git"
fi

# ----------- ensure repo & origin -----------
if [ -d .git ]; then
  # We are inside a git worktree, but origin may be missing
  if git remote get-url origin >/dev/null 2>&1; then
    echo "[ok] origin already exists -> $(git remote get-url origin)"
  else
    echo "[fix] adding origin -> $CLONE_URL"
    git remote add origin "$CLONE_URL"
  fi
else
  # No .git — initialize a repo and bind it to origin (shallow for speed)
  echo "[init] creating git repo and binding origin -> $CLONE_URL"
  git init
  git remote add origin "$CLONE_URL"
  # fetch just the branch tip
  git fetch --depth=1 origin "$BRANCH"
  # create local branch tracking remote
  git checkout -B "$BRANCH" "FETCH_HEAD"
fi

# ----------- safety / consistency -----------
# Avoid “dubious ownership” in some sandboxes
git config --global --add safe.directory "$(pwd)" || true

# If submodules exist and sandbox strips SSH, force HTTPS for GitHub submodules
if [ "$PROTO" = "https" ]; then
  git config --global url."https://github.com/".insteadOf "git@github.com:"
fi

# ----------- verify connectivity -----------
if git ls-remote --exit-code origin HEAD >/dev/null 2>&1; then
  echo "[ok] connected to origin"
else
  echo "[err] cannot reach origin or permissions are wrong"
  echo "      check REPO_SLUG and GH_TOKEN scopes/fine-grained repo selection"
  exit 2
fi

# Optional: set repo default for gh even without origin (helps commands like gh pr list outside worktree context)
export GH_REPO="${REPO_SLUG}"

echo "[ready] git+gh are wired; origin restored."
```


## `run/setup_playwright.sh`
```bash
#!/usr/bin/env bash
# Setup Playwright for CI on Debian/Ubuntu runners.
# - Installs OS deps (package manager + fonts)
# - Installs Playwright browsers and their Linux dependencies
# - Supports pnpm/npm/yarn workspaces

set -euo pipefail

log() { printf "\033[1;32m[playwright-setup]\033[0m %s\n" "$*"; }

# 0) Detect package manager (Debian/Ubuntu expected in most CI)
if command -v apt-get >/dev/null 2>&1; then
  PKG=apt-get
else
  echo "Unsupported runner (needs apt-get). Use the official Playwright Docker images instead." >&2
  exit 1
fi

# 1) Base system deps that Playwright recommends (fonts, libs)
#    (install-deps covers most libs; fonts help rendering)
log "Installing base system packages…"
sudo apt-get update -y
sudo apt-get install -y --no-install-recommends \
  ca-certificates curl git \
  fonts-liberation fonts-noto-color-emoji \
  libasound2t64 libatk-bridge2.0-0 libatk1.0-0 \
  libatspi2.0-0 libcups2 libdbus-1-3 libdrm2 \
  libgbm1 libgtk-3-0 libgtk-4-1 libnspr4 libnss3 \
  libu2f-udev libx11-6 libx11-xcb1 libxcb1 libxcomposite1 \
  libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 \
  libxrandr2 libxrender1 libxss1 libxtst6 xdg-utils

# 2) Ensure node + package manager are present (CI images often have node)
if ! command -v node >/dev/null 2>&1; then
  echo "Node.js not found; install Node before this script." >&2
  exit 1
fi

# Prefer pnpm if present
PM="pnpm"
if ! command -v pnpm >/dev/null 2>&1; then
  if command -v npm >/dev/null 2>&1; then PM="npm"
  elif command -v yarn >/dev/null 2>&1; then PM="yarn"
  else
    echo "No pnpm/npm/yarn found." >&2
    exit 1
  fi
fi

# 3) Install Playwright browsers + OS dependencies in one go
#    --with-deps pulls the distro-specific packages playwright needs on Linux.
#    (Supported Ubuntu/Debian versions only.)
log "Installing Playwright browsers and Linux dependencies…"
npx --yes playwright install --with-deps

# (Optional) force install specific browsers only:
# npx --yes playwright install --with-deps chromium firefox webkit

# 4) Print cache location (useful if you decide to cache anyway)
log "Playwright cache:"
if [ -d "$HOME/.cache/ms-playwright" ]; then
  du -hs "$HOME/.cache/ms-playwright"/* || true
fi

log "Playwright setup complete."
```

## `run/standup_chroma_nohup.sh`

```bash
#!/usr/bin/env bash
# start chroma if not running
if ! curl -fsS http://127.0.0.1:8000/api/v2/heartbeat >/dev/null 2>&1; then
  nohup uvx --from chromadb chroma run --host 127.0.0.1 --port 8000 >"$ART_DIR/chromadb_nohup.txt" 2>&1 &
fi

if ! timeout 60s bash -c 'until curl -fsS http://127.0.0.1:8000/api/v2/heartbeat >/dev/null; do sleep 1; done'; then
  echo "ChromaDB failed to become healthy in 60s" | tee -a "$ART_DIR/chromadb_health.txt" >&2
  exit 1
fi
```

## `run/nx_artifacts.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail

ART_ROOT="${ART_ROOT:-docs/reports/codex_cloud}"
ART_DIR="$ART_ROOT/nx"
mkdir -p "$ART_DIR"

# Detect Nx
if ! pnpm exec nx --version >/dev/null 2>&1; then
  echo "Nx not found; skipping Nx artifacts" | tee "$ART_DIR/skipped.txt"
  exit 0
fi

NX_VERSION="$(pnpm exec nx --version || echo unknown)"
BASE="${NX_BASE:-origin/main}"
HEAD="${NX_HEAD:-HEAD}"

# ---------- Affected projects ----------
AFFECTED_TXT="$ART_DIR/affected_projects.txt"
AFFECTED_JSON="$ART_DIR/affected_projects.json"

set +e
pnpm exec nx show projects --affected --base="$BASE" --head="$HEAD" \
  >"$AFFECTED_TXT" 2>"$ART_DIR/affected_projects.stderr"
SHOW_RC=$?
set -e

# Fallback for older Nx (<19): print-affected
if [ "$SHOW_RC" -ne 0 ]; then
  set +e
  pnpm exec nx print-affected --select=projects --base="$BASE" --head="$HEAD" \
    >"$AFFECTED_TXT" 2>>"$ART_DIR/affected_projects.stderr" || true
  set -e
fi

# Normalize to JSON array for agents
if command -v jq >/dev/null 2>&1; then
  jq -Rs 'split("\n") | map(select(length>0))' "$AFFECTED_TXT" >"$AFFECTED_JSON"
else
  echo '[]' >"$AFFECTED_JSON"
fi

AFFECTED_COUNT=$(wc -l <"$AFFECTED_TXT" | tr -d ' ' || echo 0)

# ---------- Graph artifact ----------
# Produces an HTML (with embedded data) you can open or attach
pnpm exec nx graph --affected --base="$BASE" --head="$HEAD" \
  --file="$ART_DIR/affected-graph.html" >/dev/null 2>&1 || true

# ---------- Targets: build, lint, test ----------
targets=(build lint test)
declare -A rcs
for t in "${targets[@]}"; do
  LOG="$ART_DIR/${t}.log"
  set +e
  /usr/bin/time -p pnpm exec nx affected -t "$t" \
    --base="$BASE" --head="$HEAD" \
    --parallel --output-style=stream >"$LOG" 2>&1
  rcs[$t]=$?
  set -e
done

# Always produce ESLint JSON (consistent artifact for agents)
set +e
pnpm exec eslint --cache -f json . >"$ART_DIR/eslint.json" 2>"$ART_DIR/eslint.stderr"
ESLINT_JSON_RC=$?
set -e

# ---------- Summary ----------
if command -v jq >/dev/null 2>&1; then
  jq -n \
    --arg now "$(date -Is)" \
    --arg nx_version "$NX_VERSION" \
    --arg base "$BASE" \
    --arg head "$HEAD" \
    --arg affected_file "$AFFECTED_TXT" \
    --arg affected_json "$AFFECTED_JSON" \
    --arg graph_file "$ART_DIR/affected-graph.html" \
    --arg build_log "$ART_DIR/build.log" \
    --arg lint_log "$ART_DIR/lint.log" \
    --arg test_log "$ART_DIR/test.log" \
    --arg eslint_json "$ART_DIR/eslint.json" \
    --argjson affected_count "${AFFECTED_COUNT:-0}" \
    --argjson rc_build "${rcs[build]:-0}" \
    --argjson rc_lint  "${rcs[lint]:-0}"  \
    --argjson rc_test  "${rcs[test]:-0}"  \
    --argjson rc_eslint "$ESLINT_JSON_RC" \
    '{
      timestamp: $now,
      nx: { version: $nx_version, base: $base, head: $head },
      affected: { count: $affected_count, list_file: $affected_file, list_json: $affected_json, graph_html: $graph_file },
      targets: {
        build: { rc: $rc_build, log: $build_log },
        lint:  { rc: $rc_lint,  log: $lint_log },
        test:  { rc: $rc_test,  log: $test_log }
      },
      eslint: { json_file: $eslint_json, rc: $rc_eslint },
      advice: [
        "Open build/lint/test logs to see failures (rc != 0).",
        "Open affected-graph.html to visualize impacted projects.",
        "Use affected_projects.json for quick programmatic routing."
      ]
    }' >"$ART_DIR/summary.json"
else
  echo "Install jq to generate summary.json" | tee -a "$ART_DIR/summary.warn"
fi

echo "Nx artifacts:"
echo "  - $ART_DIR/affected_projects.txt"
echo "  - $ART_DIR/affected_projects.json"
echo "  - $ART_DIR/affected-graph.html"
echo "  - $ART_DIR/build.log"
echo "  - $ART_DIR/lint.log"
echo "  - $ART_DIR/test.log"
echo "  - $ART_DIR/eslint.json"
echo "  - $ART_DIR/summary.json (if jq available)"

# ---------- Exit policy ----------
STRICT="${NX_STRICT:-0}"  # 0 = always exit 0; 1 = fail at end if any target failed
if [ "$STRICT" -ne 0 ]; then
  if [ "${rcs[build]:-0}" -ne 0 ] || [ "${rcs[lint]:-0}" -ne 0 ] || [ "${rcs[test]:-0}" -ne 0 ] || [ "$ESLINT_JSON_RC" -ne 0 ]; then
    exit 1
  fi
fi
exit 0
```
