---
uuid: "5298b6fe-c48c-4562-9e0c-17f588bc4d8d"
title: "2025.10.02.12.54.43"
slug: "20251002125443"
status: "rejected"
priority: "P3"
tags: ["docops", "labeled"]
created_at: "2025-10-10T03:23:55.971Z"
estimates:
  complexity: ""
  scale: ""
  time_to_completion: ""
---







## üóÇ Source

- Path: docs/labeled/2025.10.02.12.54.43.md

## üìù Context Summary

12:10 PM]GoblinSlayer
: I like the idea of everyone having their own personal AI that communicates on a larger scale to come up with creative solution solutions for common issues
[12:15 PM]Error
: What kinda graphics card do you have?
[12:15 PM]Error
: Cause you were askin about obsidian's llm stuff.
You can give it an openAI API key and you pay per word,
[12:16 PM]Error
: or you can use a tool like Ollama, or GPT4all to host a local language model
[12:16 PM]Error
: Llama3.1 or 3.2 are both good places to start experimenting with those
[12:17 PM]Error
: On windows I might lean towards gpt4all
[12:17 PM]Error
: as your local server
[12:18 PM]Error
: my 4070 ti has 8gb of vram, which translates to being able to use a model with between 6 and 12b parameters
[12:21 PM]Error
: I like Gemma3 for my personal use cases (That is the model that powers duck) it's multimodal, so it can handle image inputs, it's created by google, so it's like gemni lite. It's smart, maybe smarter than most models of equivolent sizes (same for gemini) but most people notice that it is not as good at "executing" on tasks. Google models tend to have mental breakdowns when they fail. They're way more open about be

## üìã Tasks

- [ ] Draft actionable subtasks from the summary
- [ ] Define acceptance criteria
- [ ] Link back to related labeled docs






