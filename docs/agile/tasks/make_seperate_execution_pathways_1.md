---
uuid: "4af34fd8-8f94-4013-ad4f-61bd0ce13c78"
title: "make seperate execution pathways 1 md md"
slug: "make_seperate_execution_pathways_1"
status: "done"
priority: "P3"
labels: ["execution", "make", "pathways", "seperate"]
created_at: "2025-10-12T19:03:19.228Z"
estimates:
  complexity: ""
  scale: ""
  time_to_completion: ""
---




































































































































































## ğŸ› ï¸ Description

I have a GPU on my desktop, the target production environment, but testing environments don't
They may not even be able to use transformers from the looks of it in node.

We had to get rid of the default chroma embeddings function to make the embeder service work

We may have to make a seperate service for embeddings in python.

I think that was mostly a javascript problem.

If we just don't do any ML in js for  now,  we shouldn't have any problems.



---

## ğŸ¯ Goals

- Define clear objectives for "Add Ollama formally to pipeline".

---

## ğŸ“¦ Requirements

- [ ] Detail requirements.

---

## ğŸ“‹ Subtasks

- [ ] Outline steps to implement.

---

## ğŸ”— Related Epics
```
#framework-core
```
---

## â›“ï¸ Blocked By

Nothing

## â›“ï¸ Blocks

Nothing

---

## ğŸ” Relevant Links

- [[kanban]]
#done



































































































































































