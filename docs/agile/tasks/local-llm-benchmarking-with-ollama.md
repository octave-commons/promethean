---
uuid: "d962a299-fe73-4fe5-a7c6-93dde8bbb55f"
title: "local-llm-benchmarking-with-ollama"
slug: "local-llm-benchmarking-with-ollama"
status: "incoming"
priority: "P3"
labels: ["docops", "labeled"]
created_at: "2025-10-12T19:03:19.225Z"
estimates:
  complexity: ""
  scale: ""
  time_to_completion: ""
---




































































































































































## ðŸ—‚ Source

- Path: docs/labeled/local-llm-benchmarking-with-ollama.md

## ðŸ“ Context Summary

---
uuid: a5baf674-4b06-4af2-886e-9228909d814a
created_at: '2025-10-07T21:55:08Z'
title: 2025.10.07.21.55.08
filename: Local LLM Benchmarking with Ollama
description: >-
  This guide explores running and benchmarking local LLMs using Ollama, focusing
  on models like Qwen3, DeepSeek, and Gemma. It covers practical steps for
  evaluation and benchmarking on limited hardware, emphasizing models that fit
  within GPU memory constraints.
tags:
  - ollama
  - local-llm
  - benchmarking
  - qwen3
  - deepseek
  - gemma
  - gpu-constrained
---
https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker
https://cline.bot/blog/local-models-amd
https://www.reddit.com/r/LocalLLaMA/comments/1o0ifyr/glm_46_air_is_coming/
https://docs.unsloth.ai/new/gpt-oss-how-to-run-and-fine-tune
https://docs.unsloth.ai/models/deepseek-v3.1-how-to-run-locally
https://github.com/matt-c1/llama-3-quant-comparison?tab=readme-ov-file
https://ollama.com/library/smollm2
https://github.com/hendrycks/test
https://github.com/unslothai/unsloth
https://docs.unsloth.ai/models/gemma-3-how-to-run-and-fine-tune/gemma-3n-how-to-run-and-fine-tune
https://ollama.com/library/gemma3n
https://huggingface.co/BasedBase/Qwen

## ðŸ“‹ Tasks

- [ ] Draft actionable subtasks from the summary
- [ ] Define acceptance criteria
- [ ] Link back to related labeled docs



































































































































































