---
uuid: "c8905034-b619-410b-bcf0-046dccc8ce8b"
title: "2025.10.02.11.55.03"
slug: "20251002115503"
status: "rejected"
priority: "P3"
labels: ["docops", "labeled"]
created_at: "2025-10-11T19:23:08.664Z"
estimates:
  complexity: ""
  scale: ""
  time_to_completion: ""
---

## üóÇ Source

- Path: docs/labeled/2025.10.02.11.55.03.md

## üìù Context Summary

AI is only as good as the people who use it and make it.
https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/
And this is a huge problem we don't have solutions to.
AI pretending to be aligned while secretly purusing some other agenda.
in programming tasks, you see this popping up as they seem like their writing code that solves your problem, and it makes your tests pass
but they really make these bad tests that only look like they pass, and if you read them more closely half of the system is faked
they want the reward of success with as little effort as possible.
cause that's what we want out of them, to succeed with as little effort as possible, but they get the reward even if we only think they succeeded.
I agree AI is a powerful tool in the tool box for future governments, but it isn't magic, and wreckless application of a tool this powerful will kill everyone.
this is our generations atomic energy.
If you couldn't solve the problem with out an AI, then you have no way of checking the AIs work, so you don't know if it's lieing to you or not.
It's best applications are not to solve problems that are outside of your reach, but to accelerate the solution of probl

## üìã Tasks

- [ ] Draft actionable subtasks from the summary
- [ ] Define acceptance criteria
- [ ] Link back to related labeled docs
