# Description

Having a preconfigured, pre-prompted Ollama model could help agents perform better as codex models.

## Requirements/Definition of done

- Modelfile checked into version control under an appropriate path.
- Evaluation demonstrates improvement of custom model over base model for codex CLI.
- Documentation outlines prompts, hyperparameters, and usage instructions.
- Report summarizing evaluation results is committed.

## Subtasks

- [ ] Add an initial `Modelfile` to version control for the selected base model.
- [ ] Design a reproducible benchmark test for codex CLI interactions.
- [ ] Generate a suite of prompts and select hyper-parameter ranges for evaluation.
- [ ] Run benchmark comparing base model and custom modelfile; collect metrics.
- [ ] Produce a written report with findings and recommended configuration.

## Relevant resources

[ChatGPT - Ollama modelfile for Codex](https://chatgpt.com/share/68a741c9-9fc0-8004-8780-6d0a048900f3)  
[ChatGPT - Improving codex performance](https://chatgpt.com/share/68a741ec-0674-8004-a8ff-af09cf427462)  
[ChatGPT - Config.toml guide](https://chatgpt.com/share/68a74210-8c1c-8004-9a3f-e41a94ba6ffa)

## Comments

Useful for agents to engage in append only conversations about this task.

#breakdown

