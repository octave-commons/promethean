---
nexus: nexus-ai-chat-importer
plugin_version: "1.2.0"
provider: chatgpt
aliases: "eww chatgpt login limits"
conversation_id: 68aa0a48-5644-8321-bd8a-38363bd020fc
create_time: 08/23/2025 at 1:36 PM
update_time: 08/23/2025 at 1:41 PM
---

# Title: eww chatgpt login limits

Created: 08/23/2025 at 1:36 PM
Last Updated: 08/23/2025 at 1:41 PM
Chat URL: https://chat.openai.com/c/68aa0a48-5644-8321-bd8a-38363bd020fc


>[!nexus_user] **User** - 08/23/2025 at 1:36 PM
> So... I have a crazy idea... I want to use eww to interact with the chatgpt website, but I don't know if I can login with this.
<!-- UID: 2b16617c-7d59-4306-a194-22665c41ddc1 -->




>[!nexus_agent] **Assistant** - 08/23/2025 at 1:36 PM
> Thatâ€™s not too crazy actually â€” people have used **eww (Emacs Web Wowser)** for all sorts of web logins. The snag is that ChatGPTâ€™s site relies heavily on **JavaScript and complex authentication flows (OAuth via Auth0, cookies, CSRF tokens, etc.)**. 
> 
> Some constraints youâ€™ll run into:
> 
> - **eww doesnâ€™t support JavaScript.** This is the biggest blocker. The login process for ChatGPT requires JS for rendering the login form, handling redirects, and exchanging tokens.
> - Even if you could load the login form HTML, the auth flow wonâ€™t complete without JS to call the API endpoints in the right sequence.
> - Once logged in, ChatGPTâ€™s frontend is React-based, so eww wouldnâ€™t render or allow interaction.
> 
> But, you *can* cheat a bit:
> 
> 1. **Use API tokens instead of the website** 
>  - If your goal is to interact with ChatGPT from Emacs, the more realistic route is calling the OpenAI API (with your API key stored in your config or a `.authinfo.gpg` file).
>  - There are packages like [`gptel`](https://github.com/karthink/gptel), [`chatgpt-shell`](https://github.com/xenodium/chatgpt-shell), or even writing a thin wrapper around `url-retrieve`.
> 
> 2. **Headless browser login, then feed eww the cookies** 
>  - Use a headless browser like `chromium --headless --remote-debugging-port=...` or Puppeteer/Playwright to log in and extract the `__Secure-next-auth.session-token` cookie.
>  - Inject that cookie into ewwâ€™s session so that requests appear authenticated. This lets you fetch *some* pages, but they still wonâ€™t render right because of the JS requirement.
> 
> 3. **Local bridge** 
>  - Run a background Node.js/Python service that uses your logged-in browser session (via Puppeteer, Playwright, or Selenium). 
>  - Talk to it from Emacs via `request.el` or `websocket.el`. 
>  - That way eww or an Emacs buffer can â€œfeelâ€ like itâ€™s interacting with the website, but really youâ€™re proxied through a full browser.
> 
> So, bottom line: **direct login in eww wonâ€™t work** (no JS). But you can totally make Emacs your ChatGPT client â€” just not through eww alone. 
> 
> ðŸ‘‰ Question for you: are you imagining this as a **purely fun hack (browse chatgpt.com in eww)**, or more like a **serious workflow (chat with GPT from inside Emacs)**? I can show you how to wire it up either way.
<!-- UID: 9a1adc90-6ee4-4ba2-ad8f-71c02183473d -->

---




>[!nexus_user] **User** - 08/23/2025 at 1:38 PM
> if I use an api key, I have to pay based on token usage?
<!-- UID: 07f6de48-8b6c-44b0-888b-bc76cdbef888 -->




>[!nexus_agent] **Assistant** - 08/23/2025 at 1:38 PM
> Exactly, yeah â€” if you go the **API key route**, youâ€™re billed per token used (input + output). 
> 
> - **ChatGPT website / app** (what youâ€™re using right now with Plus): flat monthly subscription, no metering that you see. 
> - **OpenAI API with an API key**: pure pay-per-use, and the bill depends on the model and number of tokens. For example:
>  - GPT-4o: around $2.50 per million input tokens and $10 per million output tokens. 
>  - GPT-4o-mini: much cheaper, around $0.15 input / $0.60 output per million. 
> 
> So if you wire up Emacs to the API directly, you bypass the subscription UX, but you get a metered bill. If you stick to the web interface (through a browser or a proxy service), you stay on the flat subscription but you canâ€™t really integrate cleanly into Emacs. 
> 
> There is a third hacky option some people do: **reuse the web session token** (like the `__Secure-next-auth.session-token` cookie). That way you can make requests that look like they come from the website, but OpenAI hasnâ€™t published a stable API for that, so itâ€™s brittle and may break often. 
> 
> Do you want me to map out what it would look like if you tried to keep using your **Plus subscription** inside Emacs (by hijacking session cookies), vs what it would look like to just go API-key route?
<!-- UID: 49da3dd8-a448-4ea7-a914-e773527ccc3c -->

---




>[!nexus_user] **User** - 08/23/2025 at 1:38 PM
> I have... no idea how many tokens I've used in the chats we have had...
<!-- UID: 5158bf12-16bb-4bb4-aef6-0e8af461949c -->




>[!nexus_agent] **Assistant** - 08/23/2025 at 1:38 PM
> Thatâ€™s the catch â€” in the **ChatGPT website/app** you never see a token meter, so it feels â€œfreeâ€ once you pay the flat Plus fee. 
> 
> But under the hood, everything you and I have said back and forth **does get tokenized**. A â€œtokenâ€ is roughly 4 characters of English text on average (so 75 words â‰ˆ 100 tokens). Both **your messages** and **my responses** count toward the total. 
> 
> If you were using the **API**, every single request would show up on your bill. A few ballpark numbers: 
> 
> - **Short Q&A (like this one):** ~200â€“400 tokens round trip. 
> - **Long back-and-forth (multi-paragraph answers):** easily 1kâ€“2k tokens per turn. 
> - **Big dumps (like code files, essays, transcripts):** can shoot up into the tens of thousands of tokens fast. 
> 
> So if you look at our chats here â€” where you often paste big hunks of code, specs, or conceptual notes â€” some of those exchanges would be several thousand tokens each. On API pricing, youâ€™d *feel* it. 
> 
> ðŸ‘‰ If you want, I can take a sample of one of our long conversations, tokenize it like the API would, and give you an estimate of how many tokens (and how much $$) it would have been. Want me to do that?
<!-- UID: bb8e76cd-58d3-4de8-a3a1-ad24210993be -->

---




>[!nexus_user] **User** - 08/23/2025 at 1:39 PM
> sure
<!-- UID: f503546f-5ef0-40d6-bf8f-9059dfc0c318 -->




>[!nexus_agent] **Assistant** - 08/23/2025 at 1:39 PM
> Short answer: yeahâ€”on the API you pay per token (input + output). The exact $ depends on the model. Current posted prices (per 1M tokens): **GPTâ€‘4o: $5 input / $20 output**, **GPTâ€‘4oâ€‘mini: $0.60 input / $2.40 output**. cite
> 
> Hereâ€™s what a few â€œtypicalâ€ sessions would have cost on the API:
> 
> - **Light chat** (~3,000 input + 1,500 output tokens) 
>  - GPTâ€‘4o â‰ˆ **$0.045** (0.003MÃ—$5 + 0.0015MÃ—$20) 
>  - 4oâ€‘mini â‰ˆ **$0.0054** (0.003MÃ—$0.60 + 0.0015MÃ—$2.40)
> 
> - **Code review** (~15,000 input + 5,000 output) 
>  - GPTâ€‘4o â‰ˆ **$0.175** 
>  - 4oâ€‘mini â‰ˆ **$0.021**
> 
> - **Heavy session** (~60,000 input + 20,000 output) 
>  - GPTâ€‘4o â‰ˆ **$0.70** 
>  - 4oâ€‘mini â‰ˆ **$0.084**
> 
> If you want a **precise estimate for one of our long threads**, paste any chunk of it here and tell me roughly how long my replies were (or paste those too). Iâ€™ll tally tokens and give you an exact cost using the current pricing. (I can also show the math stepâ€‘byâ€‘step if you like.)
<!-- UID: 674deebd-07e3-4048-a322-2c3cca0accab -->

---




>[!nexus_user] **User** - 08/23/2025 at 1:40 PM
> and... what bout gpt5?
<!-- UID: e2f33a9e-319c-4a5c-94df-947a99c791f2 -->




>[!nexus_agent] **Assistant** - 08/23/2025 at 1:40 PM
> You got it! Here's the straight scoop on **GPT-5**â€”what it is, how you can access it, and how the API pricing stacks up.
> 
> ---
> 
> ## What Is GPT-5?
> 
> - **Launch date**: August 7, 2025; itâ€™s OpenAIâ€™s new flagship model, replacing GPT-4, GPT-4o, GPT-4.5, and others citeturn0news22turn0news26turn0news23.
> - Itâ€™s a **unified, multimodal model**â€”it intelligently routes between â€œfastâ€ and â€œdeep-thinkingâ€ sub-models based on the taskâ€™s complexity citeturn0news26turn0news23.
> - Available to **all ChatGPT users** (free, Plus, Pro), with Pro users unlocking higher usage limits and â€œProâ€ tier capabilities citeturn0news22turn0news23turn0news26.
> 
> ---
> 
> ## GPT-5 API Pricing (per 1 million tokens)
> 
> Hereâ€™s the breakdown for developers using the OpenAI API:
> 
> | Model Variant | Input Cost | Output Cost | Cached Input Cost |
> |-----------------------|---------------|------------------|-------------------|
> | **GPT-5 (standard)** | $1.25 | $10.00 | $0.125 |
> | **GPT-5 mini** | $0.25 | $2.00 | $0.025 |
> | **GPT-5 nano** | $0.05 | $0.40 | $0.005 |
> 
> - The â€œcached inputâ€ cost applies to repeats of input recently usedâ€”OpenAI applies about a **90% discount** to reused inputs citeturn0news22.
> - GPT-5 is notably **much cheaper per token than GPT-4o**, especially on input costs cite.
> 
> ---
> 
> ## ChatGPT Subscriptions & GPT-5 Access
> 
> Here's how GPT-5 access lines up across ChatGPT plans:
> 
> - **Free users**: Access to GPT-5 and mini versions, but with **usage limits** citeturn0news22turn0news23.
> - **Plus ($20/month)**: Higher usage caps, access to â€œThinkingâ€ modes, and features like file uploads and web browsing citeturn0news25turn0news26.
> - **Pro ($200/month)**: **Unlimited GPT-5 Pro**, deeper reasoning modes, early feature access, and integrations (e.g. Gmail, Google Calendar) citeturn0news9turn0news26turn0news23turn0news27.
> - In India, there's now a budget **ChatGPT Go** plan (~â‚¹399/month or ~$5), which also includes access to GPT-5 (plus minibots and multimodal features) citeturn0news11turn0news14.
> 
> ---
> 
> ## TL;DR Summary
> 
> - **Released**: August 7, 2025, GPT-5 replaces older GPT models; free and paid users now use it by default citeturn0news22turn0news23turn0news26.
> - **API Pricing** (per million tokens): 
>  - GPT-5: $1.25 input / $10 output (cached input: $0.125) 
>  - Mini: $0.25 / $2 (cached: $0.025) 
>  - Nano: $0.05 / $0.40 (cached: $0.005) citeturn0news22turn0news23turn0news26.
> - **ChatGPT Plans**: 
>  - Free â†’ capped access 
>  - Plus â†’ more usage, â€œThinkingâ€ modes 
>  - Pro â†’ unlimited â€œProâ€ reasoning access & tool integrations 
>  - India-specific â€œGoâ€ plan provides lower-cost access and GPT-5 features citeturn0news11turn0news14turn0news25turn0news26.
> 
> ---
> 
> ### What Next?
> 
> Want to estimate how much a session would cost using GPT-5 on the API, or help figure out which variant fits your use case best? Just say the wordâ€”I can break it down, token by token.
> 
> Also, if you're considering using ChatGPT inside Emacs (via the API), GPT-5's much cheaper token prices mean youâ€™d get more value for your money compared to older models.
> 
> Let me know what you're aiming forâ€”casual chat, code deep dives, or lightweight summariesâ€”and I can recommend the most cost-effective option!
> 
> navlistFurther readingturn0news22,turn0news26,turn0news9
<!-- UID: 432003b3-95e7-44e5-81b1-2b63913884c5 -->

---


